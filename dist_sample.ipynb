{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11896ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from scipy.stats import gamma, lognorm, norm, skewnorm\n",
    "import random\n",
    "import os\n",
    "import rasterio\n",
    "from scipy.ndimage import uniform_filter\n",
    "from rasterio.features import geometry_mask\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def sample_categorical_census(df: pd.DataFrame, category_col: str, value_col: str, ignore_categories: list):\n",
    "    \"\"\"\n",
    "    Sample from a categorical distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter ignored categories\n",
    "    if ignore_categories:\n",
    "        df = df[~df[category_col].isin(ignore_categories)]\n",
    "\n",
    "    totals = df.groupby(category_col)[value_col].sum()\n",
    "    probs = totals / totals.sum()\n",
    "\n",
    "    samples = np.random.choice(\n",
    "        probs.index.to_numpy(),\n",
    "        size=1,\n",
    "        p=probs.to_numpy()\n",
    "    )\n",
    "\n",
    "    return samples[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51942825",
   "metadata": {},
   "source": [
    "# Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0bd531",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('data/watercourse/Watercourse.shp')\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15decdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('data/road/RoadLink.shp')\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370f26dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('data/road/RoadLink.shp')\n",
    "\n",
    "major_roads = gdf[gdf[\"function\"].isin([\"A Road\", \"Motorway\"])]\n",
    "\n",
    "# Plot value counts for these two categories\n",
    "major_roads[\"function\"].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Major Roads\")\n",
    "plt.xlabel(\"Function\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e105d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create overall grid shapefile\n",
    "# needs to recrop area using boundary shapefile for handling updated shapefile/tiff files (GM_shapefile/CAUTH_MAY_2025_EN_BSC.shp)\n",
    "# ignore cell if goes past boundary\n",
    "# cells of size 1km x 1km?\n",
    "# center point of each cell to be used for distance calculations\n",
    "''' \n",
    "data/watercourse/Watercourse.shp\n",
    "- closest watercourse to centre of cell (m)\n",
    "- density of watercourses in cell\n",
    "data/flood_risk/rofsw_4bandPolygon/merged_rofsw_4bandPolygon.shp\n",
    "- confidence-weighted average risk\n",
    "data/elevation.tif\n",
    "- average elevation in cell (m)\n",
    "data/impervious_surface.tif\n",
    "- fraction of impervious surface in cell\n",
    "data/historic_flood_map/Historic_Flood_MapPolygon.shp\n",
    "- if cell has been flooded in the past\n",
    "data/road/RoadLink.shp\n",
    "- closest major road to centre of cell (km)\n",
    "- density of roads in cell\n",
    "data/hospital_locations/hospital_locations.shp\n",
    "- distance to nearest hospital (km)\n",
    "'''\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import box\n",
    "from shapely.ops import unary_union\n",
    "from rasterio.mask import mask\n",
    "import rasterio\n",
    "\n",
    "CELL_SIZE = 1000 # in m\n",
    "WATERCOURSE = \"data/watercourse/Watercourse.shp\" # line geometries\n",
    "FLOOD_RISK = \"data/flood_risk/rofsw_4bandPolygon/merged_rofsw_4bandPolygon.shp\" # flood risk polygons with risk_band and confidence attributes\n",
    "ELEVATION = \"data/elevation.tif\" # metres above sea level\n",
    "IMPERVIOUS_SURFACE = \"data/impervious_surface.tif\" # each pixel represents year identified\n",
    "HISTORIC_FLOOD = \"data/historic_flood_map/Historic_Flood_MapPolygon.shp\"\n",
    "ROAD = \"data/road/RoadLink.shp\"\n",
    "HOSPITAL = \"data/hospital_locations/hospital_locations.shp\"\n",
    "BOUNDARY = \"GM_shapefile/CAUTH_MAY_2025_EN_BSC.shp\"\n",
    "OUTPUT = \"data/grid/grid.shp\"\n",
    "\n",
    "RISK_SCORES = {\"Very low\": 1, \"Low\": 2, \"Medium\": 3, \"High\": 4}\n",
    "\n",
    "# Load data\n",
    "water = gpd.read_file(WATERCOURSE).set_crs(epsg=27700, allow_override=True)\n",
    "risk = gpd.read_file(FLOOD_RISK).set_crs(epsg=27700, allow_override=True)\n",
    "'''with rasterio.open(\"data/elevation.tif\") as src:\n",
    "    elevation = src.read(1)\n",
    "with rasterio.open(\"data/impervious_surface.tif\") as src:\n",
    "    impervious = src.read(1)'''\n",
    "historic = gpd.read_file(HISTORIC_FLOOD).set_crs(epsg=27700, allow_override=True)\n",
    "road = gpd.read_file(ROAD).set_crs(epsg=27700, allow_override=True)\n",
    "hospital = gpd.read_file(HOSPITAL).set_crs(epsg=27700, allow_override=True)\n",
    "boundary = gpd.read_file(BOUNDARY).set_crs(epsg=27700, allow_override=True)\n",
    "\n",
    "# Create 1km x 1km grid covering the boundary extent\n",
    "minx, miny, maxx, maxy = boundary.total_bounds  \n",
    "xs = np.arange(minx, maxx, CELL_SIZE)\n",
    "ys = np.arange(miny, maxy, CELL_SIZE)\n",
    "\n",
    "grid = gpd.GeoDataFrame(\n",
    "    geometry=[box(x, y, x + CELL_SIZE, y + CELL_SIZE) for x in xs for y in ys],\n",
    "    crs=\"EPSG:27700\"\n",
    ")\n",
    "\n",
    "# Keep only cells that intersect the boundary\n",
    "grid = grid[grid.geometry.within(boundary.geometry.union_all())]\n",
    "\n",
    "###################\n",
    "## Watercourse density (km of watercourse per km²)\n",
    "print('Watercourse density')\n",
    "grid[\"water_dens\"] = 0.0\n",
    "cell_area_km2 = (CELL_SIZE * CELL_SIZE) / 1e6  # km²\n",
    "for i, cell in grid.geometry.items():\n",
    "    # Clip watercourses to the current cell\n",
    "    inter = water.geometry.intersection(cell)\n",
    "\n",
    "    # Sum lengths of clipped geometries\n",
    "    length_m = sum(geom.length for geom in inter if not geom.is_empty)\n",
    "    grid.at[i, \"water_dens\"] = (length_m / 1000) / cell_area_km2\n",
    "\n",
    "###################\n",
    "## Closest watercourse distance \n",
    "print('Watercourse distance')\n",
    "# Union all watercourse geometries\n",
    "water_union = unary_union(water.geometry)\n",
    "grid[\"water_dist\"] = grid.geometry.centroid.distance(water_union)\n",
    "\n",
    "###################\n",
    "## Flood risk (calculates risk score for each cell, sum(area*risk*confidence) / sum(area*confidence), confidence-weighted average risk)\n",
    "print(\"Flood risk\")\n",
    "\n",
    "# Ensure same CRS\n",
    "# Add cell id\n",
    "grid = grid.reset_index(drop=True)\n",
    "grid[\"cell_id\"] = grid.index\n",
    "\n",
    "# Spatial overlay ONCE\n",
    "inter = gpd.overlay(\n",
    "    risk,\n",
    "    grid[[\"cell_id\", \"geometry\"]],\n",
    "    how=\"intersection\"\n",
    ")\n",
    "\n",
    "if inter.empty:\n",
    "    grid[\"risk_score\"] = 0.0\n",
    "else:\n",
    "    # Area\n",
    "    inter[\"area\"] = inter.geometry.area\n",
    "\n",
    "    # Numeric risk + confidence\n",
    "    inter[\"risk_value\"] = inter[\"risk_band\"].map(RISK_SCORES).fillna(0)\n",
    "    inter[\"conf_weight\"] = inter[\"confidence\"] / 10\n",
    "\n",
    "    # Weighted components\n",
    "    inter[\"num\"] = inter[\"area\"] * inter[\"risk_value\"] * inter[\"conf_weight\"]\n",
    "    inter[\"den\"] = inter[\"area\"] * inter[\"conf_weight\"]\n",
    "\n",
    "    # Aggregate per cell\n",
    "    agg = (inter.groupby(\"cell_id\")[[\"num\", \"den\"]].sum().reset_index())\n",
    "\n",
    "    # Compute score safely\n",
    "    agg[\"risk_score\"] = agg[\"num\"] / agg[\"den\"]\n",
    "\n",
    "    # Assign back\n",
    "    grid[\"risk_score\"] = 0.0\n",
    "    grid.loc[agg[\"cell_id\"], \"risk_score\"] = agg[\"risk_score\"].values\n",
    "\n",
    "\n",
    "###################\n",
    "## Elevation\n",
    "print('Elevation')\n",
    "grid[\"elevation\"] = np.nan\n",
    "with rasterio.open(\"data/elevation.tif\") as src:\n",
    "    for i, cell in grid.iterrows():    \n",
    "        out_image, out_transform = mask(src, [cell.geometry], crop=True)\n",
    "        out_data = out_image[0]\n",
    "        grid.at[i, \"elevation\"] = out_data.mean()\n",
    "\n",
    "###################\n",
    "## Impervious surface\n",
    "print('Impervious surface')\n",
    "grid[\"impervious\"] = np.nan\n",
    "with rasterio.open(\"data/impervious.tif\") as src:\n",
    "    print(src.crs)\n",
    "    for i, cell in grid.iterrows():\n",
    "        out_image, _ = mask(src, [cell.geometry], crop=True)\n",
    "        out_data = out_image[0]\n",
    "        total_pixels = out_data.size\n",
    "        if total_pixels > 0:\n",
    "            impervious_pixels = np.count_nonzero(out_data != 0)\n",
    "            grid.at[i, \"impervious\"] = (impervious_pixels / total_pixels)\n",
    "\n",
    "###################\n",
    "## Historic flood event\n",
    "print('Historic flood event')\n",
    "grid[\"historic\"] = 0\n",
    "for i, cell in grid.iterrows():\n",
    "    # Intersect historic flood polygons with the cell\n",
    "    inter = gpd.overlay(historic, gpd.GeoDataFrame(geometry=[cell.geometry], crs=grid.crs), how=\"intersection\")\n",
    "    if inter.empty:\n",
    "        continue\n",
    "    flooded_area = inter.geometry.area.sum()\n",
    "    # Binary flag: > 50% flooded\n",
    "    if flooded_area / (CELL_SIZE**2) > 0.5:\n",
    "        grid.at[i, \"historic\"] = 1\n",
    "\n",
    "###################\n",
    "## Road density\n",
    "print('Road density')\n",
    "grid[\"road_dens\"] = 0.0\n",
    "cell_area_km2 = (CELL_SIZE * CELL_SIZE) / 1e6  # km²\n",
    "for i, cell in grid.geometry.items():\n",
    "    # Clip roads to the current cell\n",
    "    inter = road.geometry.intersection(cell)\n",
    "\n",
    "    # Sum lengths of clipped geometries\n",
    "    length_m = sum(geom.length for geom in inter if not geom.is_empty)\n",
    "    grid.at[i, \"road_dens\"] = (length_m / 1000) / cell_area_km2\n",
    "\n",
    "###################\n",
    "## Closest main road distance \n",
    "print('Road distance')\n",
    "major_roads = road[road[\"function\"].isin([\"A Road\", \"Motorway\"])].copy()\n",
    "grid[\"centroid\"] = grid.geometry.centroid\n",
    "nearest = gpd.sjoin_nearest(\n",
    "    grid.set_geometry(\"centroid\"),\n",
    "    major_roads[[\"geometry\"]],\n",
    "    how=\"left\",\n",
    "    distance_col=\"road_dist\"\n",
    ")\n",
    "grid[\"road_dist\"] = nearest.groupby(nearest.index)[\"road_dist\"].first() / 1000\n",
    "grid = grid.set_geometry(\"geometry\").drop(columns=[\"centroid\"])\n",
    "\n",
    "###################\n",
    "## Hospital proximity\n",
    "print('Hospital proximity')\n",
    "hosp_union = unary_union(hospital.geometry)\n",
    "grid[\"hospital\"] = grid.geometry.centroid.distance(hosp_union) / 1000\n",
    "\n",
    "# Save output\n",
    "grid[[\"water_dens\", \"water_dist\", \"risk_score\", \"elevation\", \"impervious\", \"historic\", \"road_dens\", \"road_dist\", \"hospital\", \"geometry\"]].to_file(OUTPUT)\n",
    "print(f\"Saved 1km grid to {OUTPUT}\")\n",
    "\n",
    "grid[[\"water_dens\", \"water_dist\", \"risk_score\", \"elevation\", \"impervious\", \"historic\", \"road_dens\", \"road_dist\", \"hospital\", \"geometry\"]].to_csv('temp.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4626e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import box\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "CELL_SIZE = 1000  # metres\n",
    "CELL_AREA_M2 = CELL_SIZE ** 2\n",
    "CELL_AREA_KM2 = CELL_AREA_M2 / 1e6\n",
    "\n",
    "WATERCOURSE = \"data/watercourse/Watercourse.shp\"\n",
    "FLOOD_RISK = \"data/flood_risk/rofsw_4bandPolygon/merged_rofsw_4bandPolygon.shp\"\n",
    "ELEVATION = \"data/elevation.tif\"\n",
    "IMPERVIOUS = \"data/impervious.tif\"\n",
    "HISTORIC_FLOOD = \"data/historic_flood_map/Historic_Flood_MapPolygon.shp\"\n",
    "ROAD = \"data/road/RoadLink.shp\"\n",
    "HOSPITAL = \"data/hospital_locations/hospital_locations.shp\"\n",
    "BOUNDARY = \"GM_shapefile/CAUTH_MAY_2025_EN_BSC.shp\"\n",
    "\n",
    "OUTPUT = \"data/grid/grid.shp\"\n",
    "\n",
    "RISK_SCORES = {\"Very low\": 1, \"Low\": 2, \"Medium\": 3, \"High\": 4}\n",
    "\n",
    "def build_grid(boundary):\n",
    "    minx, miny, maxx, maxy = boundary.total_bounds\n",
    "\n",
    "    xs = np.arange(minx, maxx, CELL_SIZE)\n",
    "    ys = np.arange(miny, maxy, CELL_SIZE)\n",
    "\n",
    "    grid = gpd.GeoDataFrame(\n",
    "        geometry=[box(x, y, x + CELL_SIZE, y + CELL_SIZE) for x in xs for y in ys],\n",
    "        crs=\"EPSG:27700\"\n",
    "    )\n",
    "\n",
    "    grid = grid[grid.geometry.within(boundary.geometry.union_all())]\n",
    "    grid[\"cell_id\"] = grid.index\n",
    "    return grid\n",
    "\n",
    "\n",
    "'''def line_density(grid, lines, colname):\n",
    "    inter = gpd.overlay(\n",
    "        grid[[\"cell_id\", \"geometry\"]],\n",
    "        lines[[\"geometry\"]],\n",
    "        how=\"intersection\"\n",
    "    )\n",
    "    inter[\"length_m\"] = inter.geometry.length\n",
    "\n",
    "    agg = inter.groupby(\"cell_id\")[\"length_m\"].sum()\n",
    "    grid[colname] = (agg / 1000 / CELL_AREA_KM2).reindex(grid.cell_id).fillna(0)\n",
    "    return grid'''\n",
    "\n",
    "def line_density_loop(grid, lines, colname, cell_size):\n",
    "    grid[colname] = 0.0\n",
    "    cell_area_km2 = (cell_size * cell_size) / 1e6  # km²\n",
    "    for i, cell in grid.geometry.items():\n",
    "        inter = lines.geometry.intersection(cell)\n",
    "        length_m = sum(geom.length for geom in inter if not geom.is_empty)\n",
    "        grid.at[i, colname] = (length_m / 1000) / cell_area_km2\n",
    "    return grid\n",
    "\n",
    "\n",
    "def nearest_distance(grid, targets, colname, km=True):\n",
    "    centroids = grid.copy()\n",
    "    centroids[\"geometry\"] = centroids.geometry.centroid\n",
    "\n",
    "    nearest = gpd.sjoin_nearest(\n",
    "        centroids,\n",
    "        targets[[\"geometry\"]],\n",
    "        how=\"left\",\n",
    "        distance_col=colname\n",
    "    )\n",
    "\n",
    "    dist = nearest.groupby(nearest.index)[colname].first()\n",
    "    if km:\n",
    "        dist = dist / 1000\n",
    "\n",
    "    grid[colname] = dist\n",
    "    return grid\n",
    "\n",
    "\n",
    "def flood_risk_score(grid, risk):\n",
    "    inter = gpd.overlay(\n",
    "        grid[[\"cell_id\", \"geometry\"]],\n",
    "        risk,\n",
    "        how=\"intersection\"\n",
    "    )\n",
    "\n",
    "    if inter.empty:\n",
    "        grid[\"risk_score\"] = 0.0\n",
    "        return grid\n",
    "\n",
    "    inter[\"area\"] = inter.geometry.area\n",
    "    inter[\"risk_value\"] = inter[\"risk_band\"].map(RISK_SCORES).fillna(0)\n",
    "    inter[\"conf_weight\"] = inter[\"confidence\"] / 10\n",
    "\n",
    "    inter[\"num\"] = inter[\"area\"] * inter[\"risk_value\"] * inter[\"conf_weight\"]\n",
    "    inter[\"den\"] = inter[\"area\"] * inter[\"conf_weight\"]\n",
    "\n",
    "    agg = inter.groupby(\"cell_id\")[[\"num\", \"den\"]].sum()\n",
    "    grid[\"risk_score\"] = (agg[\"num\"] / agg[\"den\"]).reindex(grid.cell_id).fillna(0)\n",
    "    return grid\n",
    "\n",
    "\n",
    "def zonal_mean(grid, raster_path, colname):\n",
    "    stats = zonal_stats(\n",
    "        grid.geometry,\n",
    "        raster_path,\n",
    "        stats=\"mean\",\n",
    "        nodata=0\n",
    "    )\n",
    "    grid[colname] = [s[\"mean\"] for s in stats]\n",
    "    return grid\n",
    "\n",
    "\n",
    "def zonal_fraction_nonzero(grid, raster_path, colname):\n",
    "    stats = zonal_stats(\n",
    "        grid.geometry,\n",
    "        raster_path,\n",
    "        stats=[\"count\", \"nodata\"],\n",
    "        add_stats={\"nonzero\": lambda x: np.count_nonzero(x)}\n",
    "    )\n",
    "    grid[colname] = [\n",
    "        s[\"nonzero\"] / s[\"count\"] if s[\"count\"] else 0\n",
    "        for s in stats\n",
    "    ]\n",
    "    return grid\n",
    "\n",
    "\n",
    "def historic_flood_flag(grid, historic):\n",
    "    inter = gpd.overlay(\n",
    "        grid[[\"cell_id\", \"geometry\"]],\n",
    "        historic,\n",
    "        how=\"intersection\"\n",
    "    )\n",
    "    inter[\"area\"] = inter.geometry.area\n",
    "    flooded = inter.groupby(\"cell_id\")[\"area\"].sum()\n",
    "\n",
    "    grid[\"historic\"] = (\n",
    "        flooded / CELL_AREA_M2 > 0.5\n",
    "    ).reindex(grid.cell_id).fillna(False).astype(int)\n",
    "\n",
    "    return grid\n",
    "\n",
    "\n",
    "# LOAD DATA\n",
    "print(\"Loading data...\")\n",
    "\n",
    "water = gpd.read_file(WATERCOURSE).set_crs(epsg=27700, allow_override=True)\n",
    "risk = gpd.read_file(FLOOD_RISK).set_crs(epsg=27700, allow_override=True)\n",
    "historic = gpd.read_file(HISTORIC_FLOOD).set_crs(epsg=27700, allow_override=True)\n",
    "road = gpd.read_file(ROAD).set_crs(epsg=27700, allow_override=True)\n",
    "hospital = gpd.read_file(HOSPITAL).set_crs(epsg=27700, allow_override=True)\n",
    "boundary = gpd.read_file(BOUNDARY).set_crs(epsg=27700, allow_override=True)\n",
    "\n",
    "# GRID\n",
    "print(\"Building grid...\")\n",
    "grid = build_grid(boundary)\n",
    "grid.to_file(\"data/grid/grid_step_01.shp\")\n",
    "\n",
    "# LINE DENSITIES\n",
    "print(\"Calculating watercourse density...\")\n",
    "#grid = line_density(grid, water, \"water_dens\")\n",
    "grid = line_density_loop(grid, water, \"water_dens\", CELL_SIZE)\n",
    "\n",
    "print(\"Calculating road density...\")\n",
    "#grid = line_density(grid, road, \"road_dens\")\n",
    "grid = line_density_loop(grid, road, \"road_dens\", CELL_SIZE)\n",
    "\n",
    "# NEAREST DISTANCES\n",
    "print(\"Calculating nearest watercourse distance...\")\n",
    "grid = nearest_distance(grid, water, \"water_dist\", km=False)\n",
    "\n",
    "print(\"Calculating nearest hospital distance...\")\n",
    "grid = nearest_distance(grid, hospital, \"hospital\")\n",
    "\n",
    "print(\"Calculating nearest major road distance...\")\n",
    "major_roads = road[road[\"function\"].isin([\"A Road\", \"Motorway\"])]\n",
    "grid = nearest_distance(grid, major_roads, \"road_dist\")\n",
    "\n",
    "# FLOOD RISK\n",
    "print(\"Calculating flood risk score...\")\n",
    "grid = flood_risk_score(grid, risk)\n",
    "\n",
    "# RASTER FEATURES\n",
    "print(\"Calculating elevation...\")\n",
    "grid = zonal_mean(grid, ELEVATION, \"elevation\")\n",
    "\n",
    "print(\"Calculating impervious fraction...\")\n",
    "grid = zonal_fraction_nonzero(grid, IMPERVIOUS, \"impervious\")\n",
    "\n",
    "# HISTORIC FLOOD\n",
    "print(\"Calculating historic flood flag...\")\n",
    "grid = historic_flood_flag(grid, historic)\n",
    "\n",
    "# SAVE OUTPUT\n",
    "cols = [\n",
    "    \"water_dens\",\n",
    "    \"water_dist\",\n",
    "    \"risk_score\",\n",
    "    \"elevation\",\n",
    "    \"impervious\",\n",
    "    \"historic\",\n",
    "    \"road_dens\",\n",
    "    \"road_dist\",\n",
    "    \"hospital\",\n",
    "    \"geometry\"\n",
    "]\n",
    "\n",
    "grid[cols].to_file(OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf4b04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load grids\n",
    "grid1 = gpd.read_file(\"data/grid/grid.shp\")\n",
    "grid2 = gpd.read_file(\"data/grid/grid2.shp\")\n",
    "\n",
    "# Features to plot\n",
    "features = [\n",
    "    \"water_dens\",\n",
    "    \"water_dist\",\n",
    "    \"risk_score\",\n",
    "    \"elevation\",\n",
    "    \"impervious\",\n",
    "    \"historic\",\n",
    "    \"road_dens\",\n",
    "    \"road_dist\",\n",
    "    \"hospital\",\n",
    "]\n",
    "\n",
    "# Output directory\n",
    "out_dir = \"outputs/heatmaps_comparison\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Loop through features\n",
    "for col in features:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Grid 1\n",
    "    grid1.plot(\n",
    "        column=col,\n",
    "        cmap=\"viridis\",\n",
    "        legend=True,\n",
    "        edgecolor=\"none\",\n",
    "        ax=axes[0]\n",
    "    )\n",
    "    axes[0].set_title(f\"{col} (Grid 1)\")\n",
    "    axes[0].axis(\"off\")\n",
    "    \n",
    "    # Grid 2\n",
    "    grid2.plot(\n",
    "        column=col,\n",
    "        cmap=\"viridis\",\n",
    "        legend=True,\n",
    "        edgecolor=\"none\",\n",
    "        ax=axes[1]\n",
    "    )\n",
    "    axes[1].set_title(f\"{col} (Grid 2)\")\n",
    "    axes[1].axis(\"off\")\n",
    "    \n",
    "    plt.suptitle(f\"Comparison of {col}\")\n",
    "    \n",
    "    # Save figure\n",
    "    out_path = os.path.join(out_dir, f\"{col}_comparison.png\")\n",
    "    plt.show()\n",
    "    #plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd989d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load CSV\n",
    "gdf = gpd.read_file('data/grid/grid.shp')\n",
    "\n",
    "# Columns to include\n",
    "cols = ['water_dens','water_dist','risk_score','elevation','impervious',\n",
    "        'historic_flood','road_dens','road_dist','hospital_dist']\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr = gdf[cols].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
    "plt.title(\"Correlation Heatmap of Grid Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da0865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from overall grid shapefile\n",
    "gdf = gpd.read_file('data/grid/grid.shp')\n",
    "features = [\n",
    "    \"water_dens\", \"water_dist\", \"risk_score\", \"elevation\",\n",
    "    \"impervious\", \"historic\", \"road_dens\", \"road_dist\", \"hospital\"\n",
    "]\n",
    "\n",
    "def sample_cell_with_noise(gdf, features, noise_scale=0.05):\n",
    "    row = gdf.sample(1).iloc[0]\n",
    "    sample = {}\n",
    "    for f in features:\n",
    "        val = row[f]\n",
    "        noise = np.random.normal(0, noise_scale * abs(val + 1e-6))\n",
    "        sample[f] = max(val + noise, 0)\n",
    "    return sample\n",
    "\n",
    "def sample_neighborhood(gdf, features, k=5):\n",
    "    cell = gdf.sample(1)\n",
    "    dists = gdf.geometry.distance(cell.geometry.iloc[0])\n",
    "    neighbors = gdf.loc[dists.nsmallest(k).index]\n",
    "    return neighbors[features].mean().to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1567f536",
   "metadata": {},
   "source": [
    "### Soil moisture saturation (WORK IN PREC and TEMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868df05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid resolution larger than the overal grid cell size\n",
    "'''\n",
    "Choose pixel that contains the overall grid cell chosen, sample from normal distribution of time-series values for the pixel\n",
    "'''\n",
    "\n",
    "tiff_files = sorted(glob.glob(\"data/soil_moisture/*.tif\"))\n",
    "\n",
    "stack = []\n",
    "profile = None\n",
    "\n",
    "for f in tiff_files:\n",
    "    with rasterio.open(f) as src:\n",
    "        if profile is None:\n",
    "            profile = src.profile\n",
    "        data = src.read(1).astype(np.float32)\n",
    "        nodata = src.nodata\n",
    "        if nodata is not None:\n",
    "            data[data == nodata] = np.nan\n",
    "        stack.append(data)\n",
    "\n",
    "# Shape: (time, rows, cols)\n",
    "stack = np.stack(stack, axis=0)\n",
    "\n",
    "time, rows, cols = stack.shape\n",
    "\n",
    "i = random.randint(0, rows-1)\n",
    "j = random.randint(0, cols-1)\n",
    "\n",
    "values = stack[:, i, j]\n",
    "values = values[~np.isnan(values)]  # remove nodata\n",
    "\n",
    "# Normal distribution\n",
    "mu, sigma = norm.fit(values)\n",
    "\n",
    "soil_sample = norm.rvs(mu, sigma, size=1)[0]\n",
    "\n",
    "print(f\"Random pixel chosen: ({i},{j})\")\n",
    "print(soil_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0363a0",
   "metadata": {},
   "source": [
    "# Temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b54132",
   "metadata": {},
   "source": [
    "### 1. URBAN RURAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef215539",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Bernoulli\n",
    "'''\n",
    "\n",
    "urban = pd.read_csv(\"data/urban_rural.csv\")\n",
    "counts = urban['Urban_rural_flag'].value_counts()\n",
    "urban_probs = counts / counts.sum()\n",
    "p_urban = urban_probs['Urban']\n",
    "urban_sample = np.random.binomial(n=1, p=p_urban, size=1)[0]\n",
    "print(urban_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139eeedf",
   "metadata": {},
   "source": [
    "### 2. POPULATION DENSITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69cbb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lognorm\n",
    "Dependencies: Urban/rural\n",
    "'''\n",
    "\n",
    "popden = pd.read_csv(\"data/population_density.csv\", dtype={\"LAD2021\": \"string\", \"OA21CD\": \"string\", \"Total\": \"Int64\"})\n",
    "merged = popden.merge(urban, on=\"OA21CD\", how=\"left\")\n",
    "popden_urbanrural = merged[['LAD2021','OA21CD','Total','Urban_rural_flag']]\n",
    "\n",
    "flag = 'urban' if urban_sample == 1 else 'rural'\n",
    "popden_total  = popden_urbanrural[popden_urbanrural[\"Urban_rural_flag\"].str.lower() == flag][\"Total\"]\n",
    "\n",
    "log = np.log(popden_total)\n",
    "\n",
    "mu, sigma = log.mean(), log.std()\n",
    "\n",
    "popden_sample = np.random.lognormal(mean=mu, sigma=sigma, size=1)[0]\n",
    "print(popden_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e293e3",
   "metadata": {},
   "source": [
    "### 3. DISABILITY RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f93de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Beta \n",
    "'''\n",
    "\n",
    "disability = pd.read_csv(\"data/disabled.csv\")\n",
    "total_disability = disability.groupby('Disability (3 categories)')['Observation'].sum()\n",
    "#disability_probs = total_disability / total_disability.sum()\n",
    "\n",
    "alpha = total_disability['Disabled under the Equality Act'] + 1\n",
    "beta = total_disability['Not disabled under the Equality Act'] + 1\n",
    "\n",
    "disabled_sample = np.random.beta(alpha, beta, size=1)[0]\n",
    "print(disabled_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a36ab1",
   "metadata": {},
   "source": [
    "### 4. ENGLISH PROFICIENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db365f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Beta \n",
    "Dependencies: Urban/rural\n",
    "'''\n",
    "\n",
    "def map_proficiency(category):\n",
    "    if category in [\n",
    "        \"Main language is English (English or Welsh in Wales)\",\n",
    "        \"Main language is not English (English or Welsh in Wales): Can speak English very well or well\"\n",
    "    ]:\n",
    "        return \"Good English Proficiency\"\n",
    "    elif category == \"Main language is not English (English or Welsh in Wales): Cannot speak English or cannot speak English well\":\n",
    "        return \"Bad English Proficiency\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "english = pd.read_csv(\"data/english_proficiency.csv\")   \n",
    "total_english = english.groupby('Proficiency in English language (4 categories)')['Observation'].sum()\n",
    "english['Proficiency_Group'] = english['Proficiency in English language (4 categories)'].apply(map_proficiency)\n",
    "grouped_english = english.groupby('Proficiency_Group')['Observation'].sum()\n",
    "#english_probs = grouped_english / grouped_english.sum()\n",
    "\n",
    "alpha = grouped_english['Good English Proficiency'] + 1\n",
    "beta = grouped_english['Bad English Proficiency'] + 1\n",
    "\n",
    "english_sample = np.random.beta(alpha, beta, size=1)[0]\n",
    "print(english_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b7efe",
   "metadata": {},
   "source": [
    "### 7. MEAN PROPERTY VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd91568",
   "metadata": {},
   "outputs": [],
   "source": [
    "property = pd.read_csv(\"data/property_value.csv\")\n",
    "property = property.dropna(subset=['price', 'property_type', 'duration'])\n",
    "property = property[property['price'] > 0]\n",
    "\n",
    "log_property = np.log(property['price'])\n",
    "shape, loc, scale = skewnorm.fit(log_property)\n",
    "sample_log = skewnorm.rvs(shape, loc=loc, scale=scale, size=1)\n",
    "property_sample = np.exp(sample_log)[0]\n",
    "print(property_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa963e",
   "metadata": {},
   "source": [
    "### 9. BUILDING AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c19213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "building_age = pd.read_csv(\"data/property_age.csv\")\n",
    "age_columns = [\n",
    "    \"BP_PRE_1900\",\"BP_1900_1918\",\"BP_1919_1929\",\"BP_1930_1939\",\n",
    "    \"BP_1945_1954\",\"BP_1955_1964\",\"BP_1965_1972\",\"BP_1973_1982\",\n",
    "    \"BP_1983_1992\",\"BP_1993_1999\",\"BP_2000_2009\",\"BP_2010_2015\"\n",
    "]\n",
    "age_totals = building_age[age_columns].sum()\n",
    "age_totals.index = [\n",
    "    \"Pre-1900\",\"1900-1918\",\"1919-1929\",\"1930-1939\",\"1945-1954\",\"1955-1964\",\n",
    "    \"1965-1972\",\"1973-1982\",\"1983-1992\",\"1993-1999\",\"2000-2009\",\"2010-2015\"\n",
    "]\n",
    "age_probs = age_totals / age_totals.sum()\n",
    "age_categories = age_totals.index.tolist()\n",
    "building_age_sample = np.random.choice(age_categories, size=1, p=age_probs)[0]\n",
    "print(building_age_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c029b19a",
   "metadata": {},
   "source": [
    "### 10. 24-Hour Precipitation and 13. Flood Depth (NOT DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation = pd.read_csv(\"data/precipitation.csv\")\n",
    "rainfall = precipitation[\"rainfall\"]\n",
    "pct_zero = (rainfall == 0).sum() / len(rainfall)\n",
    "zero_sample = np.random.binomial(n=1, p=pct_zero, size=1)[0]\n",
    "\n",
    "precipitation_nonzero = precipitation[precipitation[\"rainfall\"] != 0].copy()\n",
    "rainfall_nonzero = precipitation[\"rainfall\"]\n",
    "max_prec = max(rainfall_nonzero)\n",
    "shape, loc, scale = gamma.fit(rainfall_nonzero)\n",
    "prec_sample = 0 if zero_sample == 1 else gamma.rvs(a=shape, loc=loc, scale=scale, size=1)[0]\n",
    "print(prec_sample)\n",
    "\n",
    "'''if prec_sample == 0:\n",
    "    percentile = 0.0\n",
    "else:\n",
    "    percentile = gamma.cdf(prec_sample, a=shape, loc=loc, scale=scale)\n",
    "\n",
    "if percentile < 0.97:\n",
    "    flood_depth = 0.0\n",
    "elif percentile < 0.99:\n",
    "    flood_depth = 0.2\n",
    "elif percentile < 0.999:\n",
    "    flood_depth = 0.3\n",
    "elif percentile < 0.9999:\n",
    "    flood_depth = 0.6\n",
    "elif percentile < 0.99999:\n",
    "    flood_depth = 0.9\n",
    "else:\n",
    "    flood_depth = 1.2\n",
    "\n",
    "print(gamma.ppf(0.97, a=shape, loc=loc, scale=scale))\n",
    "print(gamma.ppf(0.99, a=shape, loc=loc, scale=scale))\n",
    "print(gamma.ppf(0.999, a=shape, loc=loc, scale=scale))\n",
    "print(gamma.ppf(0.9999, a=shape, loc=loc, scale=scale))\n",
    "print(gamma.ppf(0.99999, a=shape, loc=loc, scale=scale))\n",
    "print(flood_depth)  # in metres'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313266ca",
   "metadata": {},
   "source": [
    "### 11. Emergency Response Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e96f43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pd.read_csv(\"data/response_times.csv\")\n",
    "def hhmmss_to_hours(s):\n",
    "    h, m, sec = map(int, s.split(\":\"))\n",
    "    return h + m/60 + sec/3600\n",
    "\n",
    "c2_mean = response[\"C2_mean\"].apply(hhmmss_to_hours)\n",
    "c3_mean = response[\"C3_mean\"].apply(hhmmss_to_hours)\n",
    "c2_count = response['C2_count'].str.replace(',', '').astype(int).sum()\n",
    "c3_count = response['C3_count'].str.replace(',', '').astype(int).sum()\n",
    "c2_prob = c2_count / (c2_count + c3_count)\n",
    "c3_prob = c3_count / (c2_count + c3_count)\n",
    "response_category = np.random.choice(['C2', 'C3'], size=1, p=[c2_prob, c3_prob])[0]\n",
    "if response_category == 'C2':\n",
    "    shape, loc, scale = lognorm.fit(c2_mean, floc=0)\n",
    "else:\n",
    "    shape, loc, scale = lognorm.fit(c3_mean, floc=0)\n",
    "response_sample = lognorm.rvs(shape, loc=loc, scale=scale, size=1)[0]\n",
    "#print(response_sample) # hours\n",
    "\n",
    "popden_mean = popden_total.mean()\n",
    "if popden_sample < popden_mean: # scale based on average population density\n",
    "    popden_factor = 1 - 0.5 * ((popden_mean - popden_sample) / popden_mean)  # reduce scale\n",
    "else:\n",
    "    popden_factor = 1 + 0.5 * ((popden_sample - popden_mean) / popden_mean)\n",
    "prec_factor = np.exp(prec_sample / 50) # small rain = minimal effect, heavy rain = large effect\n",
    "print(popden_factor, prec_factor)\n",
    "adjusted_response = response_sample * popden_factor * prec_factor\n",
    "print(adjusted_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b7f2b4",
   "metadata": {},
   "source": [
    "### 14. Day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e136f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "day_sample = random.choice(days)\n",
    "print(day_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc739bae",
   "metadata": {},
   "source": [
    "### 15. Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f2b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "season = ['Winter', 'Spring', 'Summer', 'Autumn']\n",
    "season_sample = random.choice(season)\n",
    "print(season_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fcbf77",
   "metadata": {},
   "source": [
    "### 16. Holiday binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5879f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Min 28 days off annually\n",
    "'''\n",
    "p = 28 / 365\n",
    "holiday_binary_sample = 1 if random.random() < p else 0\n",
    "print(holiday_binary_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0096e91a",
   "metadata": {},
   "source": [
    "### 18. Depth-damage curve (ON HOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e26ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "913e1fd6",
   "metadata": {},
   "source": [
    "### 19. Groundwater level (WORK IN PREC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4510d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Choose random groundwater station, Gamma\n",
    "'''\n",
    "\n",
    "# mAOD\n",
    "# add prec dependency, modify ground water level based on previous prec_sample\n",
    "\n",
    "groundwater_files = [f for f in os.listdir(\"data/groundwater_level\") if f.lower().endswith(\".csv\")]\n",
    "gw_file = random.choice(groundwater_files)\n",
    "\n",
    "path = os.path.join(\"data/groundwater_level\", gw_file)\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "values = pd.to_numeric(df[\"value\"], errors=\"coerce\").dropna()\n",
    "a, loc, scale = skewnorm.fit(values)\n",
    "gw_sample = skewnorm.rvs(a, loc, scale, size=1)[0]\n",
    "\n",
    "print(f\"Selected file: {gw_file}\")\n",
    "print(gw_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef5221",
   "metadata": {},
   "source": [
    "### 20. River flow (WORK IN PREC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3240c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Random choose river station, Gamma\n",
    "'''\n",
    "\n",
    "# m3/s\n",
    "# add prec dependency, modify ground water level based on previous prec_sample\n",
    "\n",
    "river_flow_files = [f for f in os.listdir(\"data/river_flow\") if f.lower().endswith(\".csv\")]\n",
    "rf_file = random.choice(river_flow_files)\n",
    "\n",
    "path = os.path.join(\"data/river_flow\", rf_file)\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "values = pd.to_numeric(df[\"value\"], errors=\"coerce\").dropna()\n",
    "shape, loc, scale = gamma.fit(values, floc=0)\n",
    "rf_sample = gamma.rvs(a=shape, loc=loc, scale=scale, size=1)[0]\n",
    "\n",
    "print(f\"Selected file: {rf_file}\")\n",
    "print(rf_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b99169d",
   "metadata": {},
   "source": [
    "### 21. River level (WORK IN PREC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a425ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using same river station as river flow, Gamma\n",
    "'''\n",
    "# m\n",
    "# add prec dependency, modify ground water level based on previous prec_sample\n",
    "\n",
    "file_prefix = rf_file.split('-')[0]\n",
    "river_level_files = [f for f in os.listdir(\"data/river_level\") if f.lower().endswith(\".csv\")]\n",
    "for f in river_level_files:\n",
    "    if file_prefix in f:\n",
    "        rl_file = f\n",
    "        break\n",
    "    \n",
    "path = os.path.join(\"data/river_level\", rl_file)\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "values = pd.to_numeric(df[\"value\"], errors=\"coerce\").dropna()\n",
    "shape, loc, scale = gamma.fit(values, floc=0)\n",
    "rl_sample = gamma.rvs(a=shape, loc=loc, scale=scale, size=1)[0]\n",
    "\n",
    "print(f\"Selected file: {rl_file}\")\n",
    "print(rl_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c43566",
   "metadata": {},
   "source": [
    "### 24. General health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fc474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/general_health.csv')\n",
    "gen_health_sample = sample_categorical_census(df, \n",
    "                                                'General health (4 categories)', \n",
    "                                                'Observation', \n",
    "                                                ['Does not apply'])\n",
    "print(gen_health_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30e2b24",
   "metadata": {},
   "source": [
    "### 26. Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e752dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/age.csv')\n",
    "age_sample = sample_categorical_census(df,\n",
    "                                       'Age (6 categories)',\n",
    "                                       'Observation',\n",
    "                                       [])\n",
    "print(age_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b93502",
   "metadata": {},
   "source": [
    "### 27. Elderly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124dfbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "elderly_sample = 1 if age_sample == 'Aged 65 years and over' else 0\n",
    "print(elderly_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f070dc",
   "metadata": {},
   "source": [
    "### 28. Children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57649f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_sample = 1 if age_sample == 'Aged 15 years and under' else 0\n",
    "print(child_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac73470b",
   "metadata": {},
   "source": [
    "### 29. Employment history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f254f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Does not apply: Either child or in employment\n",
    "'''\n",
    "\n",
    "employ = pd.read_csv('data/employment-age.csv')\n",
    "filtered_employ = employ[employ['Age (6 categories)'] == age_sample]\n",
    "\n",
    "employ_sample = sample_categorical_census(filtered_employ,\n",
    "                                       'Employment history (4 categories)',\n",
    "                                       'Observation',\n",
    "                                       [])\n",
    "\n",
    "print(employ_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c5c3fd",
   "metadata": {},
   "source": [
    "### 30. Highest level of qualification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa60d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Does not apply is only for <15, \n",
    "'''\n",
    "qual = pd.read_csv('data/qualification-age.csv')\n",
    "filtered_qual = qual[qual['Age (6 categories)'] == age_sample]\n",
    "\n",
    "qual_sample = sample_categorical_census(filtered_qual,\n",
    "                                       'Highest level of qualification (7 categories)',\n",
    "                                       'Observation',\n",
    "                                       [])\n",
    "print(qual_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0d3246",
   "metadata": {},
   "source": [
    "### 31. Lifestage of household reference person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a93cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifestage = pd.read_csv('data/lifestage_hrp_age.csv')\n",
    "filtered_lifestage = lifestage[lifestage['Age (6 categories)'] == age_sample]\n",
    "lifestage_sample = sample_categorical_census(filtered_lifestage,\n",
    "                                       'Lifestage of Household Reference Person(13 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(lifestage_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3940b54",
   "metadata": {},
   "source": [
    "### 32. Accomodation type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7290932",
   "metadata": {},
   "outputs": [],
   "source": [
    "acco_type = pd.read_csv('data/accomodation_type.csv')\n",
    "acco_type_sample = sample_categorical_census(acco_type,\n",
    "                                       'Accommodation type (5 categories)',\n",
    "                                       'Observation',\n",
    "                                       [])\n",
    "print(acco_type_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd1facc",
   "metadata": {},
   "source": [
    "### 33. Vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ee25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle = pd.read_csv('data/vehicle.csv')\n",
    "vehicle_sample = sample_categorical_census(vehicle,\n",
    "                                       'Car or van availability (3 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(vehicle_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac8b150",
   "metadata": {},
   "source": [
    "### 34. Second address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0464c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_add = pd.read_csv('data/second_address.csv')\n",
    "second_add_sample = sample_categorical_census(second_add,\n",
    "                                       'Second address indicator (3 categories)',\n",
    "                                       'Observation',\n",
    "                                       [])\n",
    "print(second_add_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1c3eb3",
   "metadata": {},
   "source": [
    "### 35. Household size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e6d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_size = pd.read_csv('data/household_size.csv')\n",
    "house_size_sample = sample_categorical_census(house_size,\n",
    "                                       'Household size (5 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['0 people in household'])\n",
    "print(house_size_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b358c54",
   "metadata": {},
   "source": [
    "### 36. Economic activity status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406de34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Does not apply is only for <15, \n",
    "'''\n",
    "eas = pd.read_csv('data/nssec_economic_age.csv')\n",
    "filtered_eas = eas[eas['Age (6 categories)'] == age_sample]\n",
    "\n",
    "eas_sample = sample_categorical_census(filtered_eas,\n",
    "                                       'Economic activity status (4 categories)',\n",
    "                                       'Observation',\n",
    "                                       [])\n",
    "print(eas_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f2ac37",
   "metadata": {},
   "source": [
    "### 25. Ns-SeC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a15cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "nssec = pd.read_csv('data/nssec_economic_age.csv')\n",
    "filtered_nssec = nssec[nssec['Age (6 categories)'] == age_sample]\n",
    "filtered_nssec = filtered_nssec[filtered_nssec['Economic activity status (4 categories)'] == eas_sample]\n",
    "nssec_sample = sample_categorical_census(filtered_nssec, \n",
    "                                         'National Statistics Socio-economic Classification (NS-SeC) (10 categories)', \n",
    "                                         'Observation',\n",
    "                                         [])\n",
    "print(nssec_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92244d55",
   "metadata": {},
   "source": [
    "### 5. MEAN INCOME (REPLACE WEIGHTS WITH DATA-DRIVEN CHOICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3ccc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Log skewnorm \n",
    "'''\n",
    "\n",
    "from scipy.stats import skewnorm, lognorm\n",
    "\n",
    "income = pd.read_csv(\"data/mean_income.csv\")\n",
    "income['Total annual income (£)'] = (\n",
    "    income['Total annual income (£)']\n",
    "    .str.strip()        \n",
    "    .str.replace(',', '')      \n",
    "    .astype(float)       \n",
    ")\n",
    "\n",
    "log_income = np.log(income['Total annual income (£)'])\n",
    "shape, loc, scale = skewnorm.fit(log_income)\n",
    "sample_log = skewnorm.rvs(shape, loc=loc, scale=scale, size=1)\n",
    "income_sample = np.exp(sample_log)[0]\n",
    "\n",
    "NSSEC = {\n",
    "    \"L1, L2 and L3: Higher managerial, administrative and professional occupations\": 1.90,\n",
    "    \"L4, L5 and L6: Lower managerial, administrative and professional occupations\": 1.35,\n",
    "    \"L7: Intermediate occupations\": 1.00,\n",
    "    \"L8 and L9: Small employers and own account workers\": 1.10,\n",
    "    \"L10 and L11: Lower supervisory and technical occupations\": 0.90,\n",
    "    \"L12: Semi-routine occupations\": 0.75,\n",
    "    \"L13: Routine occupations\": 0.65,\n",
    "    \"L14.1 and L14.2: Never worked and long-term unemployed\": 0.40,\n",
    "    \"L15: Full-time students\": 0.35,\n",
    "    \"Does not apply\": 0.00\n",
    "}\n",
    "\n",
    "income_sample *= NSSEC[nssec_sample]\n",
    "print(income_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9351d79c",
   "metadata": {},
   "source": [
    "### 6. LOW-INCOME FRACTION (NOT DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bada3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "median = income['Total annual income (£)'].median()\n",
    "low_income_threshold = 0.6 * median\n",
    "print(low_income_threshold)\n",
    "\n",
    "variance_log_skewnorm = skewnorm.var(shape, loc=loc, scale=scale)\n",
    "\n",
    "###### PART THAT DOESNT SEEM RIGHT\n",
    "meanlog = np.log(income_sample)\n",
    "std = np.sqrt(variance_log_skewnorm)\n",
    "print(std)\n",
    "prob_low_income = lognorm.cdf(low_income_threshold, s=std, scale=np.exp(meanlog))\n",
    "print(prob_low_income)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d78a568",
   "metadata": {},
   "source": [
    "### 37. No. adults employed in household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e57113",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_adults = pd.read_csv('data/household_employed_size.csv')\n",
    "filtered_num_adults = num_adults[num_adults['Household size (5 categories)'] == house_size_sample]\n",
    "\n",
    "num_adults_sample = sample_categorical_census(filtered_num_adults,\n",
    "                                       'Number of adults in employment in household (5 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(num_adults_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a5684",
   "metadata": {},
   "source": [
    "### 38. No. disabled people household "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad57797",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_disable = pd.read_csv('data/household_disabled_size.csv')\n",
    "filtered_num_disable = num_disable[num_disable['Household size (5 categories)'] == house_size_sample]\n",
    "\n",
    "num_disable_sample = sample_categorical_census(filtered_num_disable,\n",
    "                                       'Number of disabled people in household (4 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(num_disable_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9720fd26",
   "metadata": {},
   "source": [
    "### 39. No. long-term health in household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_long = pd.read_csv('data/household_long-term_size.csv')\n",
    "filtered_num_long = num_long[num_long['Household size (5 categories)'] == house_size_sample]\n",
    "\n",
    "num_long_sample = sample_categorical_census(filtered_num_long,\n",
    "                                       'Number of people in household with a long-term heath condition but are not disabled (4 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(num_long_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ea9a4f",
   "metadata": {},
   "source": [
    "### 40. Deprived in education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a83df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_edu = pd.read_csv('data/deprived_education+deps.csv')\n",
    "filtered_dep_edu = dep_edu[dep_edu['Highest level of qualification (7 categories)'] == qual_sample]\n",
    "\n",
    "dep_edu_sample = sample_categorical_census(filtered_dep_edu,\n",
    "                                       'Household deprived in the education dimension (3 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(dep_edu_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cc1c86",
   "metadata": {},
   "source": [
    "### 41. Deprived in employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb62d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_employ = pd.read_csv('data/deprived_employment+deps.csv')\n",
    "filtered_dep_employ = dep_employ[dep_employ['Employment history (4 categories)'] == employ_sample]\n",
    "filtered_dep_employ = filtered_dep_employ[filtered_dep_employ['National Statistics Socio-economic Classification (NS-SeC) (10 categories)'] == nssec_sample]\n",
    "dep_employ_sample = sample_categorical_census(filtered_dep_employ,\n",
    "                                       'Household deprived in the employment dimension (3 categories)',\n",
    "                                       'Observation',\n",
    "                                       [])\n",
    "print(dep_employ_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515c00cf",
   "metadata": {},
   "source": [
    "### 42. Deprived in health and disability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab6d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_health = pd.read_csv('data/deprived_health+deps.csv')\n",
    "filtered_dep_health = dep_health[dep_health['Number of people in household with a long-term heath condition but are not disabled (4 categories)'] == num_long_sample]\n",
    "filtered_dep_health = filtered_dep_health[filtered_dep_health['Number of disabled people in household (4 categories)'] == num_disable_sample]\n",
    "dep_health_sample = sample_categorical_census(filtered_dep_health,\n",
    "                                       'Household deprived in the health and disability dimension (3 categories)',\n",
    "                                       'Observation',\n",
    "                                       [])\n",
    "print(dep_health_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35967c9d",
   "metadata": {},
   "source": [
    "### 43. No. of people per room in household "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea33c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_people = pd.read_csv('data/people_per_room_hsize.csv')\n",
    "filtered_num_people = num_people[num_people['Household size (5 categories)'] == house_size_sample]\n",
    "num_people_sample = sample_categorical_census(filtered_num_people,\n",
    "                                       'Number of people per room in household (5 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(num_people_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1a2168",
   "metadata": {},
   "source": [
    "### 44. Occupancy rating for rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e6a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy = pd.read_csv('data/occupancy_rating_nopeopleper.csv')\n",
    "filtered_occupancy = occupancy[occupancy['Number of people per room in household (5 categories)'] == num_people_sample]\n",
    "num_occupancy = sample_categorical_census(filtered_occupancy,\n",
    "                                       'Occupancy rating for rooms (5 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(num_occupancy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557d5f2a",
   "metadata": {},
   "source": [
    "### 45. Deprived in housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccafc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_housing = pd.read_csv('data/deprived_housing+deps.csv')\n",
    "filtered_dep_housing = dep_housing[dep_housing['Number of people per room in household (5 categories)'] == num_people_sample]\n",
    "filtered_dep_housing = filtered_dep_housing[filtered_dep_housing['Occupancy rating for rooms (5 categories)'] == num_occupancy]\n",
    "dep_housing_sample = sample_categorical_census(filtered_dep_housing,\n",
    "                                       'Household deprived in the housing dimension (3 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(dep_housing_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31f14dc",
   "metadata": {},
   "source": [
    "### 46. Household deprivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb74312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller = less deprived\n",
    "household_dep_sample = (dep_edu_sample == 'Household is deprived in the education dimension') + (dep_employ_sample == 'Household is deprived in the employment dimension') + (dep_health_sample == 'Household is deprived in the health and disability dimension') + (dep_housing_sample == 'Household is deprived in the housing dimension')\n",
    "print(household_dep_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bb8554",
   "metadata": {},
   "source": [
    "### 47. Tenure of household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0099bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "tenure = pd.read_csv('data/tenure.csv')\n",
    "tenure_sample = sample_categorical_census(tenure,\n",
    "                                       'Tenure of household (7 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(tenure_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52373c6",
   "metadata": {},
   "source": [
    "### 48. Household access to internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b324613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "linear regression\n",
    "\n",
    "household_comp_sample\n",
    "\n",
    "YEAR = 2026\n",
    "time = np.array([2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020])\n",
    "if household_comp_sample == 'One-person household: Aged 66 years and over':\n",
    "    values = np.array([36, 40, 40, 49, 53, 61, 59, 73, 80])\n",
    "elif household_comp_sample == 'One-person household: Other':\n",
    "    values = np.array([76, 74, 81, 80, 87, 88, 91, 94, 95])\n",
    "else:\n",
    "    time = np.array([1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020])\n",
    "    values = np.array([13, 25, 36, 42, 46, 49, 55, 57, 61, 65, 70, 73, 77, 80, 83, 84, 86, 89, 90, 90, 93, 96])\n",
    "\n",
    "m, b = np.polyfit(time, values, 1)\n",
    "val = m*YEAR+b\n",
    "print(val)\n",
    "\n",
    "all val > 100\n",
    "'''\n",
    "if lifestage_sample == 'Household reference person is aged 66 years or over: One-person household':\n",
    "    prob = 0.85\n",
    "else:\n",
    "    prob = 0.98\n",
    "internet_sample = np.random.binomial(n=1, p=prob)\n",
    "print(internet_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4502c8",
   "metadata": {},
   "source": [
    "### 49. Household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091e3535",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Home ownership:\n",
    "- wealth accumulation\n",
    "- tenure security\n",
    "Mortgage holders retain equity but face some financial exposure\n",
    "\n",
    "Private renters:\n",
    "- higher housing cost volatility\n",
    "- lower security\n",
    "Social renters:\n",
    "- low-income\n",
    "- benefit-dependent\n",
    "- high-deprivation populations\n",
    "'''\n",
    "TENURE_RISK = {\n",
    "    \"Owned: Owns outright\": 0.0,\n",
    "    \"Owned: Owns with a mortgage or loan or shared ownership\": 0.1,\n",
    "    \"Private rented: Private landlord or letting agency\": 0.6,\n",
    "    \"Private rented: Other private rented or lives rent free\": 0.6,\n",
    "    \"Social rented: Rents from council or Local Authority\": 0.8,\n",
    "    \"Social rented: Other social rented\": 0.8,\n",
    "}\n",
    "\n",
    "'''\n",
    "- Housing quality, space, and permanence decrease down the list\n",
    "- Flats and temporary housing show higher overcrowding and energy risk\n",
    "- Temporary structures are near-maximal risk \n",
    "'''\n",
    "ACCO_RISK = {\n",
    "    \"Whole house or bungalow: Detached\": 0.1,\n",
    "    \"Whole house or bungalow: Semi-detached\": 0.1,\n",
    "    \"Whole house or bungalow: Terraced\": 0.3,\n",
    "    \"Flat, maisonette or apartment\": 0.5,\n",
    "    \"A caravan or other mobile or temporary structure\": 0.9,\n",
    "}\n",
    "\n",
    "'''\n",
    "Single-person households:\n",
    "- income fragility\n",
    "- social isolation risk\n",
    "Two-person households:\n",
    "- risk-sharing\n",
    "Large households:\n",
    "- crowding\n",
    "- higher costs\n",
    "- child dependency\n",
    "'''\n",
    "SIZE_RISK = {\n",
    "    \"1 person in household\": 0.5,\n",
    "    \"2 people in household\": 0.2,\n",
    "    \"3 people in household\": 0.3,\n",
    "    \"4 or more people in household\": 0.6,\n",
    "}\n",
    "\n",
    "'''\n",
    "Internet access for weather warning services\n",
    "'''\n",
    "INTERNET_RISK = {\n",
    "    1: 0.0,\n",
    "    0: 0.6,\n",
    "}\n",
    "\n",
    "'''\n",
    "Risk increases with less earners\n",
    "'''\n",
    "EMPLOYMENT_RISK = {\n",
    "    \"3 or more adults in employment in household\": 0.0,\n",
    "    \"2 adults in employment in household\": 0.2,\n",
    "    \"1 adult in employment in household\": 0.5,\n",
    "    \"No adults in employment in household\": 0.9,\n",
    "}\n",
    "\n",
    "'''\n",
    "Deprivation in education, employment, health, housing\n",
    "'''\n",
    "DEPRIVATION_RISK = {\n",
    "    0: 0.0,\n",
    "    1: 0.25,\n",
    "    2: 0.5,\n",
    "    3: 0.75,\n",
    "    4: 1.0,\n",
    "}\n",
    "\n",
    "'''\n",
    "Older single households:\n",
    "- health risks\n",
    "- lower chance of internet access\n",
    "- elderly vulnerable\n",
    "Households with dependent children:\n",
    "- cost pressure\n",
    "- children vulnerable\n",
    "Child-free working-age households are most resilient\n",
    "'''\n",
    "def lifestage_risk_map(x):\n",
    "    if \"66 years or over\" in x and \"One-person\" in x:\n",
    "        return 0.7\n",
    "    if \"Dependent children\" in x:\n",
    "        return 0.6\n",
    "    if \"Two or more person household: No dependent children\" in x:\n",
    "        return 0.3\n",
    "    return 0.4\n",
    "\n",
    "tenure_risk = TENURE_RISK[tenure_sample]\n",
    "acco_risk = ACCO_RISK[acco_type_sample]\n",
    "size_risk = SIZE_RISK[house_size_sample]\n",
    "internet_risk = INTERNET_RISK[internet_sample]\n",
    "employment_risk = EMPLOYMENT_RISK[num_adults_sample]\n",
    "deprivation_risk = DEPRIVATION_RISK[household_dep_sample]\n",
    "lifestage_risk = lifestage_risk_map(lifestage_sample)\n",
    "\n",
    "'''\n",
    "Deprivation: looks at 4 factors (higher weight)\n",
    "Employment: Income stability\n",
    "Employment: Wealth and security\n",
    "Others: Secondary modifiers\n",
    "'''\n",
    "WEIGHTS = {\n",
    "    \"tenure_risk\": 0.15,\n",
    "    \"acco_risk\": 0.10,\n",
    "    \"size_risk\": 0.10,\n",
    "    \"internet_risk\": 0.10,\n",
    "    \"lifestage_risk\": 0.10,\n",
    "    \"employment_risk\": 0.20,\n",
    "    \"deprivation_risk\": 0.25,\n",
    "}\n",
    " \n",
    "risk_score = (\n",
    "    WEIGHTS[\"tenure_risk\"]       * tenure_risk +\n",
    "    WEIGHTS[\"acco_risk\"]         * acco_risk +\n",
    "    WEIGHTS[\"size_risk\"]         * size_risk +\n",
    "    WEIGHTS[\"internet_risk\"]     * internet_risk +\n",
    "    WEIGHTS[\"lifestage_risk\"]    * lifestage_risk +\n",
    "    WEIGHTS[\"employment_risk\"]   * employment_risk +\n",
    "    WEIGHTS[\"deprivation_risk\"]  * deprivation_risk\n",
    ")\n",
    "\n",
    "print('Tenure -', tenure_sample)\n",
    "print('Accomodation type -', acco_type_sample)\n",
    "print('Household size -', house_size_sample)\n",
    "print('Internet access -', internet_sample)\n",
    "print('Adults employed -', num_adults_sample)\n",
    "print('Household deprivation -', household_dep_sample)\n",
    "print('Lifestage HRP -', lifestage_sample)\n",
    "\n",
    "noise = np.random.normal(loc=0, scale=0.03) \n",
    "household_risk_score = np.clip(risk_score + noise, 0, 1)\n",
    "print(household_risk_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ecaa28",
   "metadata": {},
   "source": [
    "### 51. Ambulance handover delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f96b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97f35968",
   "metadata": {},
   "source": [
    "### 52. Hospital bed availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359537da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
