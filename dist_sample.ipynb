{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11896ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from scipy.stats import gamma, lognorm, norm\n",
    "import random\n",
    "import os\n",
    "import rasterio\n",
    "from scipy.ndimage import uniform_filter\n",
    "from rasterio.features import geometry_mask\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def sample_categorical_census(df: pd.DataFrame, category_col: str, value_col: str, ignore_categories: list):\n",
    "    \"\"\"\n",
    "    Sample from a categorical distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter ignored categories\n",
    "    if ignore_categories:\n",
    "        df = df[~df[category_col].isin(ignore_categories)]\n",
    "\n",
    "    totals = df.groupby(category_col)[value_col].sum()\n",
    "    probs = totals / totals.sum()\n",
    "\n",
    "    samples = np.random.choice(\n",
    "        probs.index.to_numpy(),\n",
    "        size=1,\n",
    "        p=probs.to_numpy()\n",
    "    )\n",
    "\n",
    "    return samples[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51942825",
   "metadata": {},
   "source": [
    "# Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe3c57f",
   "metadata": {},
   "source": [
    "### Water area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788da81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"data/watercourse_density/watercourse_density.shp\")\n",
    "length = gdf[\"length_km\"]\n",
    "pct_zero = (length == 0).sum() / len(length)\n",
    "zero_sample = np.random.binomial(n=1, p=pct_zero, size=1)[0]\n",
    "\n",
    "gdf_nonzero = gdf[gdf[\"length_km\"] != 0].copy()\n",
    "length_nonzero = gdf_nonzero[\"length_km\"]\n",
    "shape, loc, scale = gamma.fit(length_nonzero)\n",
    "length_sample = 0 if zero_sample == 1 else gamma.rvs(a=shape, loc=loc, scale=scale, size=1)[0]\n",
    "print(length_sample*1000) # metres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69bae05",
   "metadata": {},
   "source": [
    "### Distance to water "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"data/watercourse_distance/watercourse_distance.shp\")\n",
    "distance = gdf[\"distance_t\"]\n",
    "shape, loc, scale = gamma.fit(distance)\n",
    "\n",
    "max_distance = distance.max()\n",
    "epsilon = 0.01\n",
    "scale_factor = max_distance / (length_sample + epsilon)\n",
    "\n",
    "distance_sample = gamma.rvs(a=shape, loc=loc, scale=scale, size=10)\n",
    "#if length_sample == 0:\n",
    "#    distance_sample = max_distance - distance_sample\n",
    "print(distance_sample) # metres\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d9ee46",
   "metadata": {},
   "source": [
    "### Flood risk level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5dc311",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''risk_shapefile = [\n",
    "    'data/flood_risk/rofsw_4bandPolygon/merged_rofsw_4bandPolygon.shp',\n",
    "    'data/flood_risk/rofsw_4band_0_2m_depthPolygon/merged_rofsw_4band_0_2m_depthPolygon.shp',\n",
    "    'data/flood_risk/rofsw_4band_0_3m_depthPolygon/merged_rofsw_4band_0_3m_depthPolygon.shp',\n",
    "    'data/flood_risk/rofsw_4band_0_6m_depthPolygon/merged_rofsw_4band_0_6m_depthPolygon.shp',\n",
    "    'data/flood_risk/rofsw_4band_0_9m_depthPolygon/merged_rofsw_4band_0_9m_depthPolygon.shp',\n",
    "    'data/flood_risk/rofsw_4band_1_2m_depthPolygon/merged_rofsw_4band_1_2m_depthPolygon.shp'\n",
    "]\n",
    "\n",
    "gm_gdf = gpd.read_file(\"GM_shapefile/CAUTH_MAY_2025_EN_BSC.shp\")\n",
    "gm_area_km2 = gm_gdf.geometry.area.sum() / 1000000\n",
    "print('Total area of Greater Manchester:')\n",
    "print(str(gm_area_km2)+' km²')\n",
    "\n",
    "# high > 3.3%\n",
    "# medium 1-3.3% \n",
    "# low 0.1-1%\n",
    "# very low < 0.1%\n",
    "\n",
    "gdf = gpd.read_file('data/flood_risk/rofsw_4bandPolygon/merged_rofsw_4bandPolygon.shp')\n",
    "gdf[\"area_m2\"] = gdf.geometry.area\n",
    "gdf[\"area_km2\"] = gdf[\"area_m2\"] / 1000000\n",
    "total = 0\n",
    "depth_risk_prob = {}\n",
    "for depth_shapefile in risk_shapefile:\n",
    "    depth_gdf = gpd.read_file(depth_shapefile)\n",
    "    depth_gdf[\"area_m2\"] = depth_gdf.geometry.area\n",
    "    depth_gdf[\"area_km2\"] = depth_gdf[\"area_m2\"] / 1000000\n",
    "    depth_total = 0\n",
    "    risk_prob = {}\n",
    "    for risk in ['Very low' , 'Low', 'Medium', 'High']:\n",
    "        subset = depth_gdf[depth_gdf[\"risk_band\"] == risk]\n",
    "        total_area_km2 = subset[\"area_km2\"].sum()\n",
    "        depth_total += total_area_km2\n",
    "        risk_prob[risk] = float(total_area_km2 / gm_area_km2)\n",
    "    risk_prob['No Risk'] = float((gm_area_km2 - depth_total) / gm_area_km2)\n",
    "    depth_risk_prob[depth_shapefile] = risk_prob\n",
    "print(depth_risk_prob)\n",
    "\n",
    "depths = list(depth_risk_prob.keys())\n",
    "high_risk_probs = np.array([depth_risk_prob[d]['High'] for d in depths])\n",
    "high_risk_probs = high_risk_probs / high_risk_probs.sum()\n",
    "print(high_risk_probs)\n",
    "depth_choice = np.random.choice(depths, p=high_risk_probs)\n",
    "print(depth_choice)\n",
    "\n",
    "risk_probs = depth_risk_prob[depth_choice]\n",
    "risks = list(risk_probs.keys())\n",
    "risk_prob_values = np.array([risk_probs[r] for r in risks])\n",
    "risk_prob_values = risk_prob_values / risk_prob_values.sum()\n",
    "print(risk_prob_values)\n",
    "risk_choice = np.random.choice(risks, p=risk_prob_values)\n",
    "print(risk_choice)'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed54f64",
   "metadata": {},
   "source": [
    "### Elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea135f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Exclude outer bound values (0), average windows, Gamma\n",
    "'''\n",
    "\n",
    "window_size = 7 # nxn\n",
    "\n",
    "with rasterio.open(\"data/elevation.tif\") as src:\n",
    "    elevation = src.read(1)\n",
    "\n",
    "valid_mask = elevation != 0\n",
    "elev_filled = np.where(valid_mask, elevation, 0)  # set zeros to 0 for filtering\n",
    "\n",
    "# Compute sum over windows\n",
    "sum_window = uniform_filter(elev_filled.astype(float), size=window_size, mode='constant', cval=0)\n",
    "\n",
    "# Compute count of valid pixels in each window\n",
    "count_window = uniform_filter(valid_mask.astype(float), size=window_size, mode='constant', cval=0)\n",
    "\n",
    "# Compute average, avoiding division by zero\n",
    "avg_window = sum_window / np.maximum(count_window, 1)\n",
    "\n",
    "averages = avg_window.flatten()\n",
    "averages = averages[count_window.flatten() > 0]  # remove windows with all zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0685883",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages_pos = averages[averages > 0]\n",
    "shape, loc, scale = gamma.fit(averages_pos, floc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation_sample = gamma.rvs(a=shape, loc=loc, scale=scale, size=1)[0]\n",
    "\n",
    "print(f\"Total windows averaged: {len(averages)}\")\n",
    "print(elevation_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcba22b",
   "metadata": {},
   "source": [
    "### Impervious surface area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c64405",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Only pixels within boundary averaged in windows, Gamma, scales sample based on Urban/rural\n",
    "'''\n",
    "\n",
    "window_size = 7  # nxn window\n",
    "\n",
    "gdf = gpd.read_file(\"GM_shapefile/CAUTH_MAY_2025_EN_BSC.shp\")\n",
    "\n",
    "with rasterio.open(\"data/elevation.tif\") as src:\n",
    "    elevation = src.read(1)\n",
    "    transform = src.transform\n",
    "\n",
    "# Create GM mask (True inside GM)\n",
    "gm_mask = geometry_mask(geometries=gdf.geometry, transform=transform, invert=True, out_shape=elevation.shape)\n",
    "\n",
    "# Mask outside GM only\n",
    "elevation_gm = np.where(gm_mask, elevation, np.nan)\n",
    "\n",
    "# Detect windows with ANY NaN\n",
    "nan_mask = np.isnan(elevation_gm)\n",
    "nan_count = uniform_filter(nan_mask.astype(float), size=window_size, mode=\"constant\", cval=1)\n",
    "\n",
    "# Compute sum (NaNs replaced only for summation) \n",
    "sum_window = uniform_filter(np.nan_to_num(elevation_gm), size=window_size, mode=\"constant\", cval=0)\n",
    "\n",
    "# Compute average only for fully valid windows \n",
    "valid_windows = nan_count == 0\n",
    "avg_window = np.full(elevation.shape, np.nan)\n",
    "avg_window[valid_windows] = sum_window[valid_windows] / (window_size ** 2)\n",
    "\n",
    "averages = avg_window[~np.isnan(avg_window)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f222407",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages_pos = averages[averages > 0]\n",
    "shape, loc, scale = gamma.fit(averages_pos, floc=0)\n",
    "\n",
    "impervious_sample = gamma.rvs(a=shape, loc=loc, scale=scale, size=1)[0]\n",
    "\n",
    "urban_factor = 1.15  \n",
    "rural_factor = 0.85\n",
    "\n",
    "factor = urban_factor if urban_sample else rural_factor\n",
    "impervious_sample = impervious_sample * factor\n",
    "\n",
    "print(f\"Total windows averaged: {len(averages)}\")\n",
    "print(impervious_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f01f54",
   "metadata": {},
   "source": [
    "### Historic flood map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b8bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66a1a553",
   "metadata": {},
   "source": [
    "### Road network density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36bc7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c0363a0",
   "metadata": {},
   "source": [
    "# Temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b54132",
   "metadata": {},
   "source": [
    "### 1. URBAN RURAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef215539",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Bernoulli\n",
    "'''\n",
    "\n",
    "urban = pd.read_csv(\"data/urban_rural.csv\")\n",
    "counts = urban['Urban_rural_flag'].value_counts()\n",
    "urban_probs = counts / counts.sum()\n",
    "p_urban = urban_probs['Urban']\n",
    "urban_sample = np.random.binomial(n=1, p=p_urban, size=1)[0]\n",
    "print(urban_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139eeedf",
   "metadata": {},
   "source": [
    "### 2. POPULATION DENSITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69cbb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lognorm\n",
    "Dependencies: Urban/rural\n",
    "'''\n",
    "\n",
    "popden = pd.read_csv(\"data/population_density.csv\", dtype={\"LAD2021\": \"string\", \"OA21CD\": \"string\", \"Total\": \"Int64\"})\n",
    "merged = popden.merge(urban, on=\"OA21CD\", how=\"left\")\n",
    "popden_urbanrural = merged[['LAD2021','OA21CD','Total','Urban_rural_flag']]\n",
    "\n",
    "flag = 'urban' if urban_sample == 1 else 'rural'\n",
    "popden_total  = popden_urbanrural[popden_urbanrural[\"Urban_rural_flag\"].str.lower() == flag][\"Total\"]\n",
    "\n",
    "log = np.log(popden_total)\n",
    "\n",
    "mu, sigma = log.mean(), log.std()\n",
    "\n",
    "popden_sample = np.random.lognormal(mean=mu, sigma=sigma, size=1)[0]\n",
    "print(popden_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e293e3",
   "metadata": {},
   "source": [
    "### 3. DISABILITY RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f93de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Beta \n",
    "'''\n",
    "\n",
    "disability = pd.read_csv(\"data/disabled.csv\")\n",
    "total_disability = disability.groupby('Disability (3 categories)')['Observation'].sum()\n",
    "#disability_probs = total_disability / total_disability.sum()\n",
    "\n",
    "alpha = total_disability['Disabled under the Equality Act'] + 1\n",
    "beta = total_disability['Not disabled under the Equality Act'] + 1\n",
    "\n",
    "disabled_sample = np.random.beta(alpha, beta, size=1)[0]\n",
    "print(disabled_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a36ab1",
   "metadata": {},
   "source": [
    "### 4. ENGLISH PROFICIENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db365f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Beta \n",
    "Dependencies: Urban/rural\n",
    "'''\n",
    "\n",
    "def map_proficiency(category):\n",
    "    if category in [\n",
    "        \"Main language is English (English or Welsh in Wales)\",\n",
    "        \"Main language is not English (English or Welsh in Wales): Can speak English very well or well\"\n",
    "    ]:\n",
    "        return \"Good English Proficiency\"\n",
    "    elif category == \"Main language is not English (English or Welsh in Wales): Cannot speak English or cannot speak English well\":\n",
    "        return \"Bad English Proficiency\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "english = pd.read_csv(\"data/english_proficiency.csv\")   \n",
    "total_english = english.groupby('Proficiency in English language (4 categories)')['Observation'].sum()\n",
    "english['Proficiency_Group'] = english['Proficiency in English language (4 categories)'].apply(map_proficiency)\n",
    "grouped_english = english.groupby('Proficiency_Group')['Observation'].sum()\n",
    "#english_probs = grouped_english / grouped_english.sum()\n",
    "\n",
    "alpha = grouped_english['Good English Proficiency'] + 1\n",
    "beta = grouped_english['Bad English Proficiency'] + 1\n",
    "\n",
    "english_sample = np.random.beta(alpha, beta, size=1)[0]\n",
    "print(english_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b7efe",
   "metadata": {},
   "source": [
    "### 7. MEAN PROPERTY VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd91568",
   "metadata": {},
   "outputs": [],
   "source": [
    "property = pd.read_csv(\"data/property_value.csv\")\n",
    "property = property.dropna(subset=['price', 'property_type', 'duration'])\n",
    "property = property[property['price'] > 0]\n",
    "\n",
    "log_property = np.log(property['price'])\n",
    "shape, loc, scale = skewnorm.fit(log_property)\n",
    "sample_log = skewnorm.rvs(shape, loc=loc, scale=scale, size=1)\n",
    "property_sample = np.exp(sample_log)[0]\n",
    "print(property_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa963e",
   "metadata": {},
   "source": [
    "### 9. BUILDING AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c19213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "building_age = pd.read_csv(\"data/property_age.csv\")\n",
    "age_columns = [\n",
    "    \"BP_PRE_1900\",\"BP_1900_1918\",\"BP_1919_1929\",\"BP_1930_1939\",\n",
    "    \"BP_1945_1954\",\"BP_1955_1964\",\"BP_1965_1972\",\"BP_1973_1982\",\n",
    "    \"BP_1983_1992\",\"BP_1993_1999\",\"BP_2000_2009\",\"BP_2010_2015\"\n",
    "]\n",
    "age_totals = building_age[age_columns].sum()\n",
    "age_totals.index = [\n",
    "    \"Pre-1900\",\"1900-1918\",\"1919-1929\",\"1930-1939\",\"1945-1954\",\"1955-1964\",\n",
    "    \"1965-1972\",\"1973-1982\",\"1983-1992\",\"1993-1999\",\"2000-2009\",\"2010-2015\"\n",
    "]\n",
    "age_probs = age_totals / age_totals.sum()\n",
    "age_categories = age_totals.index.tolist()\n",
    "building_age_sample = np.random.choice(age_categories, size=1, p=age_probs)[0]\n",
    "print(building_age_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c029b19a",
   "metadata": {},
   "source": [
    "### 10. 24-Hour Precipitation and 13. Flood Depth (NOT DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation = pd.read_csv(\"data/precipitation.csv\")\n",
    "rainfall = precipitation[\"rainfall\"]\n",
    "pct_zero = (rainfall == 0).sum() / len(rainfall)\n",
    "zero_sample = np.random.binomial(n=1, p=pct_zero, size=1)[0]\n",
    "\n",
    "precipitation_nonzero = precipitation[precipitation[\"rainfall\"] != 0].copy()\n",
    "rainfall_nonzero = precipitation[\"rainfall\"]\n",
    "max_prec = max(rainfall_nonzero)\n",
    "shape, loc, scale = gamma.fit(rainfall_nonzero)\n",
    "prec_sample = 0 if zero_sample == 1 else gamma.rvs(a=shape, loc=loc, scale=scale, size=1)[0]\n",
    "print(prec_sample)\n",
    "\n",
    "'''if prec_sample == 0:\n",
    "    percentile = 0.0\n",
    "else:\n",
    "    percentile = gamma.cdf(prec_sample, a=shape, loc=loc, scale=scale)\n",
    "\n",
    "if percentile < 0.97:\n",
    "    flood_depth = 0.0\n",
    "elif percentile < 0.99:\n",
    "    flood_depth = 0.2\n",
    "elif percentile < 0.999:\n",
    "    flood_depth = 0.3\n",
    "elif percentile < 0.9999:\n",
    "    flood_depth = 0.6\n",
    "elif percentile < 0.99999:\n",
    "    flood_depth = 0.9\n",
    "else:\n",
    "    flood_depth = 1.2\n",
    "\n",
    "print(gamma.ppf(0.97, a=shape, loc=loc, scale=scale))\n",
    "print(gamma.ppf(0.99, a=shape, loc=loc, scale=scale))\n",
    "print(gamma.ppf(0.999, a=shape, loc=loc, scale=scale))\n",
    "print(gamma.ppf(0.9999, a=shape, loc=loc, scale=scale))\n",
    "print(gamma.ppf(0.99999, a=shape, loc=loc, scale=scale))\n",
    "print(flood_depth)  # in metres'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313266ca",
   "metadata": {},
   "source": [
    "### 11. Emergency Response Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e96f43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pd.read_csv(\"data/response_times.csv\")\n",
    "def hhmmss_to_hours(s):\n",
    "    h, m, sec = map(int, s.split(\":\"))\n",
    "    return h + m/60 + sec/3600\n",
    "\n",
    "c2_mean = response[\"C2_mean\"].apply(hhmmss_to_hours)\n",
    "c3_mean = response[\"C3_mean\"].apply(hhmmss_to_hours)\n",
    "c2_count = response['C2_count'].str.replace(',', '').astype(int).sum()\n",
    "c3_count = response['C3_count'].str.replace(',', '').astype(int).sum()\n",
    "c2_prob = c2_count / (c2_count + c3_count)\n",
    "c3_prob = c3_count / (c2_count + c3_count)\n",
    "response_category = np.random.choice(['C2', 'C3'], size=1, p=[c2_prob, c3_prob])[0]\n",
    "if response_category == 'C2':\n",
    "    shape, loc, scale = lognorm.fit(c2_mean, floc=0)\n",
    "else:\n",
    "    shape, loc, scale = lognorm.fit(c3_mean, floc=0)\n",
    "response_sample = lognorm.rvs(shape, loc=loc, scale=scale, size=1)[0]\n",
    "#print(response_sample) # hours\n",
    "\n",
    "popden_mean = popden_total.mean()\n",
    "if popden_sample < popden_mean: # scale based on average population density\n",
    "    popden_factor = 1 - 0.5 * ((popden_mean - popden_sample) / popden_mean)  # reduce scale\n",
    "else:\n",
    "    popden_factor = 1 + 0.5 * ((popden_sample - popden_mean) / popden_mean)\n",
    "prec_factor = np.exp(prec_sample / 50) # small rain = minimal effect, heavy rain = large effect\n",
    "print(popden_factor, prec_factor)\n",
    "adjusted_response = response_sample * popden_factor * prec_factor\n",
    "print(adjusted_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b7f2b4",
   "metadata": {},
   "source": [
    "### 14. Day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e136f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "day_sample = random.choice(days)\n",
    "print(day_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc739bae",
   "metadata": {},
   "source": [
    "### 15. Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f2b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "season = ['Winter', 'Spring', 'Summer', 'Autumn']\n",
    "season_sample = random.choice(season)\n",
    "print(season_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fcbf77",
   "metadata": {},
   "source": [
    "### 16. Holiday binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5879f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Min 28 days off annually\n",
    "'''\n",
    "p = 28 / 365\n",
    "holiday_binary_sample = 1 if random.random() < p else 0\n",
    "print(holiday_binary_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0096e91a",
   "metadata": {},
   "source": [
    "### 18. Depth-damage curve (ON HOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e26ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "913e1fd6",
   "metadata": {},
   "source": [
    "### 19. Groundwater level (WORK IN PREC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4510d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Choose random groundwater station, Gamma\n",
    "'''\n",
    "\n",
    "# mAOD\n",
    "# add prec dependency, modify ground water level based on previous prec_sample\n",
    "\n",
    "groundwater_files = [f for f in os.listdir(\"data/groundwater_level\") if f.lower().endswith(\".csv\")]\n",
    "gw_file = random.choice(groundwater_files)\n",
    "\n",
    "path = os.path.join(\"data/groundwater_level\", gw_file)\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "values = pd.to_numeric(df[\"value\"], errors=\"coerce\").dropna()\n",
    "a, loc, scale = skewnorm.fit(values)\n",
    "gw_sample = skewnorm.rvs(a, loc, scale, size=1)[0]\n",
    "\n",
    "print(f\"Selected file: {gw_file}\")\n",
    "print(gw_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef5221",
   "metadata": {},
   "source": [
    "### 20. River flow (WORK IN PREC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3240c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Random choose river station, Gamma\n",
    "'''\n",
    "\n",
    "# m3/s\n",
    "# add prec dependency, modify ground water level based on previous prec_sample\n",
    "\n",
    "river_flow_files = [f for f in os.listdir(\"data/river_flow\") if f.lower().endswith(\".csv\")]\n",
    "rf_file = random.choice(river_flow_files)\n",
    "\n",
    "path = os.path.join(\"data/river_flow\", rf_file)\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "values = pd.to_numeric(df[\"value\"], errors=\"coerce\").dropna()\n",
    "shape, loc, scale = gamma.fit(values, floc=0)\n",
    "rf_sample = gamma.rvs(a=shape, loc=loc, scale=scale, size=1)[0]\n",
    "\n",
    "print(f\"Selected file: {rf_file}\")\n",
    "print(rf_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b99169d",
   "metadata": {},
   "source": [
    "### 21. River level (WORK IN PREC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a425ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using same river station as river flow, Gamma\n",
    "'''\n",
    "# m\n",
    "# add prec dependency, modify ground water level based on previous prec_sample\n",
    "\n",
    "file_prefix = rf_file.split('-')[0]\n",
    "river_level_files = [f for f in os.listdir(\"data/river_level\") if f.lower().endswith(\".csv\")]\n",
    "for f in river_level_files:\n",
    "    if file_prefix in f:\n",
    "        rl_file = f\n",
    "        break\n",
    "    \n",
    "path = os.path.join(\"data/river_level\", rl_file)\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "values = pd.to_numeric(df[\"value\"], errors=\"coerce\").dropna()\n",
    "shape, loc, scale = gamma.fit(values, floc=0)\n",
    "rl_sample = gamma.rvs(a=shape, loc=loc, scale=scale, size=1)[0]\n",
    "\n",
    "print(f\"Selected file: {rl_file}\")\n",
    "print(rl_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660317e8",
   "metadata": {},
   "source": [
    "### 22. Soil moisture saturation (WORK IN PREC and TEMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23843cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Random choose pixel, sample from normal distribution of time-series values for the pixel\n",
    "'''\n",
    "\n",
    "tiff_files = sorted(glob.glob(\"data/soil_moisture/*.tif\"))\n",
    "\n",
    "stack = []\n",
    "profile = None\n",
    "\n",
    "for f in tiff_files:\n",
    "    with rasterio.open(f) as src:\n",
    "        if profile is None:\n",
    "            profile = src.profile\n",
    "        data = src.read(1).astype(np.float32)\n",
    "        nodata = src.nodata\n",
    "        if nodata is not None:\n",
    "            data[data == nodata] = np.nan\n",
    "        stack.append(data)\n",
    "\n",
    "# Shape: (time, rows, cols)\n",
    "stack = np.stack(stack, axis=0)\n",
    "\n",
    "time, rows, cols = stack.shape\n",
    "\n",
    "i = random.randint(0, rows-1)\n",
    "j = random.randint(0, cols-1)\n",
    "\n",
    "values = stack[:, i, j]\n",
    "values = values[~np.isnan(values)]  # remove nodata\n",
    "\n",
    "# Normal distribution\n",
    "mu, sigma = norm.fit(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1750bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_sample = norm.rvs(mu, sigma, size=1)[0]\n",
    "\n",
    "print(f\"Random pixel chosen: ({i},{j})\")\n",
    "print(soil_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b0128a",
   "metadata": {},
   "source": [
    "### 23. Impervious surface area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaf305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Only pixels within boundary averaged in windows, Gamma, scales sample based on Urban/rural\n",
    "'''\n",
    "\n",
    "window_size = 7  # nxn window\n",
    "\n",
    "gdf = gpd.read_file(\"GM_shapefile/CAUTH_MAY_2025_EN_BSC.shp\")\n",
    "\n",
    "with rasterio.open(\"data/elevation.tif\") as src:\n",
    "    elevation = src.read(1)\n",
    "    transform = src.transform\n",
    "\n",
    "# Create GM mask (True inside GM)\n",
    "gm_mask = geometry_mask(geometries=gdf.geometry, transform=transform, invert=True, out_shape=elevation.shape)\n",
    "\n",
    "# Mask outside GM only\n",
    "elevation_gm = np.where(gm_mask, elevation, np.nan)\n",
    "\n",
    "# Detect windows with ANY NaN\n",
    "nan_mask = np.isnan(elevation_gm)\n",
    "nan_count = uniform_filter(nan_mask.astype(float), size=window_size, mode=\"constant\", cval=1)\n",
    "\n",
    "# Compute sum (NaNs replaced only for summation) \n",
    "sum_window = uniform_filter(np.nan_to_num(elevation_gm), size=window_size, mode=\"constant\", cval=0)\n",
    "\n",
    "# Compute average only for fully valid windows \n",
    "valid_windows = nan_count == 0\n",
    "avg_window = np.full(elevation.shape, np.nan)\n",
    "avg_window[valid_windows] = sum_window[valid_windows] / (window_size ** 2)\n",
    "\n",
    "averages = avg_window[~np.isnan(avg_window)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1010ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages_pos = averages[averages > 0]\n",
    "shape, loc, scale = gamma.fit(averages_pos, floc=0)\n",
    "\n",
    "impervious_sample = gamma.rvs(a=shape, loc=loc, scale=scale, size=1)[0]\n",
    "\n",
    "urban_factor = 1.15  \n",
    "rural_factor = 0.85\n",
    "\n",
    "factor = urban_factor if urban_sample else rural_factor\n",
    "impervious_sample = impervious_sample * factor\n",
    "\n",
    "print(f\"Total windows averaged: {len(averages)}\")\n",
    "print(impervious_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c43566",
   "metadata": {},
   "source": [
    "### 24. General health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fc474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/general_health.csv')\n",
    "gen_health_sample = sample_categorical_census(df, \n",
    "                                                'General health (4 categories)', \n",
    "                                                'Observation', \n",
    "                                                ['Does not apply'])\n",
    "print(gen_health_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30e2b24",
   "metadata": {},
   "source": [
    "### 26. Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e752dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/age.csv')\n",
    "age_sample = sample_categorical_census(df,\n",
    "                                       'Age (6 categories)',\n",
    "                                       'Observation',\n",
    "                                       [])\n",
    "print(age_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b93502",
   "metadata": {},
   "source": [
    "### 27. Elderly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124dfbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "elderly_sample = 1 if age_sample == 'Aged 65 years and over' else 0\n",
    "print(elderly_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f070dc",
   "metadata": {},
   "source": [
    "### 28. Children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57649f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_sample = 1 if age_sample == 'Aged 15 years and under' else 0\n",
    "print(child_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac73470b",
   "metadata": {},
   "source": [
    "### 29. Employment history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f254f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Does not apply: Either child or in employment\n",
    "'''\n",
    "\n",
    "employ = pd.read_csv('data/employment-age.csv')\n",
    "filtered_employ = employ[employ['Age (6 categories)'] == age_sample]\n",
    "\n",
    "employ_sample = sample_categorical_census(filtered_employ,\n",
    "                                       'Employment history (4 categories)',\n",
    "                                       'Observation',\n",
    "                                       [])\n",
    "\n",
    "print(employ_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c5c3fd",
   "metadata": {},
   "source": [
    "### 30. Highest level of qualification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa60d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Does not apply is only for <15, \n",
    "'''\n",
    "qual = pd.read_csv('data/qualification-age.csv')\n",
    "filtered_qual = qual[qual['Age (6 categories)'] == age_sample]\n",
    "\n",
    "qual_sample = sample_categorical_census(filtered_qual,\n",
    "                                       'Highest level of qualification (7 categories)',\n",
    "                                       'Observation',\n",
    "                                       [])\n",
    "print(qual_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0d3246",
   "metadata": {},
   "source": [
    "### 31. Lifestage of household reference person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a93cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifestage = pd.read_csv('data/lifestage_hrp_age.csv')\n",
    "filtered_lifestage = lifestage[lifestage['Age (6 categories)'] == age_sample]\n",
    "lifestage_sample = sample_categorical_census(filtered_lifestage,\n",
    "                                       'Lifestage of Household Reference Person(13 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(lifestage_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3940b54",
   "metadata": {},
   "source": [
    "### 32. Accomodation type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7290932",
   "metadata": {},
   "outputs": [],
   "source": [
    "acco_type = pd.read_csv('data/accomodation_type.csv')\n",
    "acco_type_sample = sample_categorical_census(acco_type,\n",
    "                                       'Accommodation type (5 categories)',\n",
    "                                       'Observation',\n",
    "                                       [])\n",
    "print(acco_type_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd1facc",
   "metadata": {},
   "source": [
    "### 33. Vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ee25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle = pd.read_csv('data/vehicle.csv')\n",
    "vehicle_sample = sample_categorical_census(vehicle,\n",
    "                                       'Car or van availability (3 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(vehicle_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac8b150",
   "metadata": {},
   "source": [
    "### 34. Second address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0464c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_add = pd.read_csv('data/second_address.csv')\n",
    "second_add_sample = sample_categorical_census(second_add,\n",
    "                                       'Second address indicator (3 categories)',\n",
    "                                       'Observation',\n",
    "                                       [])\n",
    "print(second_add_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1c3eb3",
   "metadata": {},
   "source": [
    "### 35. Household size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e6d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_size = pd.read_csv('data/household_size.csv')\n",
    "house_size_sample = sample_categorical_census(house_size,\n",
    "                                       'Household size (5 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['0 people in household'])\n",
    "print(house_size_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b358c54",
   "metadata": {},
   "source": [
    "### 36. Economic activity status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406de34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Does not apply is only for <15, \n",
    "'''\n",
    "eas = pd.read_csv('data/nssec_economic_age.csv')\n",
    "filtered_eas = eas[eas['Age (6 categories)'] == age_sample]\n",
    "\n",
    "eas_sample = sample_categorical_census(filtered_eas,\n",
    "                                       'Economic activity status (4 categories)',\n",
    "                                       'Observation',\n",
    "                                       [])\n",
    "print(eas_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f2ac37",
   "metadata": {},
   "source": [
    "### 25. Ns-SeC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a15cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "nssec = pd.read_csv('data/nssec_economic_age.csv')\n",
    "filtered_nssec = nssec[nssec['Age (6 categories)'] == age_sample]\n",
    "filtered_nssec = filtered_nssec[filtered_nssec['Economic activity status (4 categories)'] == eas_sample]\n",
    "nssec_sample = sample_categorical_census(filtered_nssec, \n",
    "                                         'National Statistics Socio-economic Classification (NS-SeC) (10 categories)', \n",
    "                                         'Observation',\n",
    "                                         [])\n",
    "print(nssec_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92244d55",
   "metadata": {},
   "source": [
    "### 5. MEAN INCOME (REPLACE WEIGHTS WITH DATA-DRIVEN CHOICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3ccc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Log skewnorm \n",
    "'''\n",
    "\n",
    "from scipy.stats import skewnorm, lognorm\n",
    "\n",
    "income = pd.read_csv(\"data/mean_income.csv\")\n",
    "income['Total annual income (£)'] = (\n",
    "    income['Total annual income (£)']\n",
    "    .str.strip()        \n",
    "    .str.replace(',', '')      \n",
    "    .astype(float)       \n",
    ")\n",
    "\n",
    "log_income = np.log(income['Total annual income (£)'])\n",
    "shape, loc, scale = skewnorm.fit(log_income)\n",
    "sample_log = skewnorm.rvs(shape, loc=loc, scale=scale, size=1)\n",
    "income_sample = np.exp(sample_log)[0]\n",
    "\n",
    "NSSEC = {\n",
    "    \"L1, L2 and L3: Higher managerial, administrative and professional occupations\": 1.90,\n",
    "    \"L4, L5 and L6: Lower managerial, administrative and professional occupations\": 1.35,\n",
    "    \"L7: Intermediate occupations\": 1.00,\n",
    "    \"L8 and L9: Small employers and own account workers\": 1.10,\n",
    "    \"L10 and L11: Lower supervisory and technical occupations\": 0.90,\n",
    "    \"L12: Semi-routine occupations\": 0.75,\n",
    "    \"L13: Routine occupations\": 0.65,\n",
    "    \"L14.1 and L14.2: Never worked and long-term unemployed\": 0.40,\n",
    "    \"L15: Full-time students\": 0.35,\n",
    "    \"Does not apply\": 0.00\n",
    "}\n",
    "\n",
    "income_sample *= NSSEC[nssec_sample]\n",
    "print(income_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9351d79c",
   "metadata": {},
   "source": [
    "### 6. LOW-INCOME FRACTION (NOT DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bada3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "median = income['Total annual income (£)'].median()\n",
    "low_income_threshold = 0.6 * median\n",
    "print(low_income_threshold)\n",
    "\n",
    "variance_log_skewnorm = skewnorm.var(shape, loc=loc, scale=scale)\n",
    "\n",
    "###### PART THAT DOESNT SEEM RIGHT\n",
    "meanlog = np.log(income_sample)\n",
    "std = np.sqrt(variance_log_skewnorm)\n",
    "print(std)\n",
    "prob_low_income = lognorm.cdf(low_income_threshold, s=std, scale=np.exp(meanlog))\n",
    "print(prob_low_income)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d78a568",
   "metadata": {},
   "source": [
    "### 37. No. adults employed in household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e57113",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_adults = pd.read_csv('data/household_employed_size.csv')\n",
    "filtered_num_adults = num_adults[num_adults['Household size (5 categories)'] == house_size_sample]\n",
    "\n",
    "num_adults_sample = sample_categorical_census(filtered_num_adults,\n",
    "                                       'Number of adults in employment in household (5 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(num_adults_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a5684",
   "metadata": {},
   "source": [
    "### 38. No. disabled people household "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad57797",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_disable = pd.read_csv('data/household_disabled_size.csv')\n",
    "filtered_num_disable = num_disable[num_disable['Household size (5 categories)'] == house_size_sample]\n",
    "\n",
    "num_disable_sample = sample_categorical_census(filtered_num_disable,\n",
    "                                       'Number of disabled people in household (4 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(num_disable_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9720fd26",
   "metadata": {},
   "source": [
    "### 39. No. long-term health in household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_long = pd.read_csv('data/household_long-term_size.csv')\n",
    "filtered_num_long = num_long[num_long['Household size (5 categories)'] == house_size_sample]\n",
    "\n",
    "num_long_sample = sample_categorical_census(filtered_num_long,\n",
    "                                       'Number of people in household with a long-term heath condition but are not disabled (4 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(num_long_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ea9a4f",
   "metadata": {},
   "source": [
    "### 40. Deprived in education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a83df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_edu = pd.read_csv('data/deprived_education+deps.csv')\n",
    "filtered_dep_edu = dep_edu[dep_edu['Highest level of qualification (7 categories)'] == qual_sample]\n",
    "\n",
    "dep_edu_sample = sample_categorical_census(filtered_dep_edu,\n",
    "                                       'Household deprived in the education dimension (3 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(dep_edu_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cc1c86",
   "metadata": {},
   "source": [
    "### 41. Deprived in employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb62d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_employ = pd.read_csv('data/deprived_employment+deps.csv')\n",
    "filtered_dep_employ = dep_employ[dep_employ['Employment history (4 categories)'] == employ_sample]\n",
    "filtered_dep_employ = filtered_dep_employ[filtered_dep_employ['National Statistics Socio-economic Classification (NS-SeC) (10 categories)'] == nssec_sample]\n",
    "dep_employ_sample = sample_categorical_census(filtered_dep_employ,\n",
    "                                       'Household deprived in the employment dimension (3 categories)',\n",
    "                                       'Observation',\n",
    "                                       [])\n",
    "print(dep_employ_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515c00cf",
   "metadata": {},
   "source": [
    "### 42. Deprived in health and disability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab6d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_health = pd.read_csv('data/deprived_health+deps.csv')\n",
    "filtered_dep_health = dep_health[dep_health['Number of people in household with a long-term heath condition but are not disabled (4 categories)'] == num_long_sample]\n",
    "filtered_dep_health = filtered_dep_health[filtered_dep_health['Number of disabled people in household (4 categories)'] == num_disable_sample]\n",
    "dep_health_sample = sample_categorical_census(filtered_dep_health,\n",
    "                                       'Household deprived in the health and disability dimension (3 categories)',\n",
    "                                       'Observation',\n",
    "                                       [])\n",
    "print(dep_health_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35967c9d",
   "metadata": {},
   "source": [
    "### 43. No. of people per room in household "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea33c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_people = pd.read_csv('data/people_per_room_hsize.csv')\n",
    "filtered_num_people = num_people[num_people['Household size (5 categories)'] == house_size_sample]\n",
    "num_people_sample = sample_categorical_census(filtered_num_people,\n",
    "                                       'Number of people per room in household (5 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(num_people_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1a2168",
   "metadata": {},
   "source": [
    "### 44. Occupancy rating for rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e6a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy = pd.read_csv('data/occupancy_rating_nopeopleper.csv')\n",
    "filtered_occupancy = occupancy[occupancy['Number of people per room in household (5 categories)'] == num_people_sample]\n",
    "num_occupancy = sample_categorical_census(filtered_occupancy,\n",
    "                                       'Occupancy rating for rooms (5 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(num_occupancy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557d5f2a",
   "metadata": {},
   "source": [
    "### 45. Deprived in housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccafc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_housing = pd.read_csv('data/deprived_housing+deps.csv')\n",
    "filtered_dep_housing = dep_housing[dep_housing['Number of people per room in household (5 categories)'] == num_people_sample]\n",
    "filtered_dep_housing = filtered_dep_housing[filtered_dep_housing['Occupancy rating for rooms (5 categories)'] == num_occupancy]\n",
    "dep_housing_sample = sample_categorical_census(filtered_dep_housing,\n",
    "                                       'Household deprived in the housing dimension (3 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(dep_housing_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31f14dc",
   "metadata": {},
   "source": [
    "### 46. Household deprivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb74312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller = less deprived\n",
    "household_dep_sample = (dep_edu_sample == 'Household is deprived in the education dimension') + (dep_employ_sample == 'Household is deprived in the employment dimension') + (dep_health_sample == 'Household is deprived in the health and disability dimension') + (dep_housing_sample == 'Household is deprived in the housing dimension')\n",
    "print(household_dep_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bb8554",
   "metadata": {},
   "source": [
    "### 47. Tenure of household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0099bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "tenure = pd.read_csv('data/tenure.csv')\n",
    "tenure_sample = sample_categorical_census(tenure,\n",
    "                                       'Tenure of household (7 categories)',\n",
    "                                       'Observation',\n",
    "                                       ['Does not apply'])\n",
    "print(tenure_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52373c6",
   "metadata": {},
   "source": [
    "### 48. Household access to internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b324613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "linear regression\n",
    "\n",
    "household_comp_sample\n",
    "\n",
    "YEAR = 2026\n",
    "time = np.array([2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020])\n",
    "if household_comp_sample == 'One-person household: Aged 66 years and over':\n",
    "    values = np.array([36, 40, 40, 49, 53, 61, 59, 73, 80])\n",
    "elif household_comp_sample == 'One-person household: Other':\n",
    "    values = np.array([76, 74, 81, 80, 87, 88, 91, 94, 95])\n",
    "else:\n",
    "    time = np.array([1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020])\n",
    "    values = np.array([13, 25, 36, 42, 46, 49, 55, 57, 61, 65, 70, 73, 77, 80, 83, 84, 86, 89, 90, 90, 93, 96])\n",
    "\n",
    "m, b = np.polyfit(time, values, 1)\n",
    "val = m*YEAR+b\n",
    "print(val)\n",
    "\n",
    "all val > 100\n",
    "'''\n",
    "if lifestage_sample == 'Household reference person is aged 66 years or over: One-person household':\n",
    "    prob = 0.85\n",
    "else:\n",
    "    prob = 0.98\n",
    "internet_sample = np.random.binomial(n=1, p=prob)\n",
    "print(internet_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4502c8",
   "metadata": {},
   "source": [
    "### 49. Household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091e3535",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Home ownership:\n",
    "- wealth accumulation\n",
    "- tenure security\n",
    "Mortgage holders retain equity but face some financial exposure\n",
    "\n",
    "Private renters:\n",
    "- higher housing cost volatility\n",
    "- lower security\n",
    "Social renters:\n",
    "- low-income\n",
    "- benefit-dependent\n",
    "- high-deprivation populations\n",
    "'''\n",
    "TENURE_RISK = {\n",
    "    \"Owned: Owns outright\": 0.0,\n",
    "    \"Owned: Owns with a mortgage or loan or shared ownership\": 0.1,\n",
    "    \"Private rented: Private landlord or letting agency\": 0.6,\n",
    "    \"Private rented: Other private rented or lives rent free\": 0.6,\n",
    "    \"Social rented: Rents from council or Local Authority\": 0.8,\n",
    "    \"Social rented: Other social rented\": 0.8,\n",
    "}\n",
    "\n",
    "'''\n",
    "- Housing quality, space, and permanence decrease down the list\n",
    "- Flats and temporary housing show higher overcrowding and energy risk\n",
    "- Temporary structures are near-maximal risk \n",
    "'''\n",
    "ACCO_RISK = {\n",
    "    \"Whole house or bungalow: Detached\": 0.1,\n",
    "    \"Whole house or bungalow: Semi-detached\": 0.1,\n",
    "    \"Whole house or bungalow: Terraced\": 0.3,\n",
    "    \"Flat, maisonette or apartment\": 0.5,\n",
    "    \"A caravan or other mobile or temporary structure\": 0.9,\n",
    "}\n",
    "\n",
    "'''\n",
    "Single-person households:\n",
    "- income fragility\n",
    "- social isolation risk\n",
    "Two-person households:\n",
    "- risk-sharing\n",
    "Large households:\n",
    "- crowding\n",
    "- higher costs\n",
    "- child dependency\n",
    "'''\n",
    "SIZE_RISK = {\n",
    "    \"1 person in household\": 0.5,\n",
    "    \"2 people in household\": 0.2,\n",
    "    \"3 people in household\": 0.3,\n",
    "    \"4 or more people in household\": 0.6,\n",
    "}\n",
    "\n",
    "'''\n",
    "Internet access for weather warning services\n",
    "'''\n",
    "INTERNET_RISK = {\n",
    "    1: 0.0,\n",
    "    0: 0.6,\n",
    "}\n",
    "\n",
    "'''\n",
    "Risk increases with less earners\n",
    "'''\n",
    "EMPLOYMENT_RISK = {\n",
    "    \"3 or more adults in employment in household\": 0.0,\n",
    "    \"2 adults in employment in household\": 0.2,\n",
    "    \"1 adult in employment in household\": 0.5,\n",
    "    \"No adults in employment in household\": 0.9,\n",
    "}\n",
    "\n",
    "'''\n",
    "Deprivation in education, employment, health, housing\n",
    "'''\n",
    "DEPRIVATION_RISK = {\n",
    "    0: 0.0,\n",
    "    1: 0.25,\n",
    "    2: 0.5,\n",
    "    3: 0.75,\n",
    "    4: 1.0,\n",
    "}\n",
    "\n",
    "'''\n",
    "Older single households:\n",
    "- health risks\n",
    "- lower chance of internet access\n",
    "- elderly vulnerable\n",
    "Households with dependent children:\n",
    "- cost pressure\n",
    "- children vulnerable\n",
    "Child-free working-age households are most resilient\n",
    "'''\n",
    "def lifestage_risk_map(x):\n",
    "    if \"66 years or over\" in x and \"One-person\" in x:\n",
    "        return 0.7\n",
    "    if \"Dependent children\" in x:\n",
    "        return 0.6\n",
    "    if \"Two or more person household: No dependent children\" in x:\n",
    "        return 0.3\n",
    "    return 0.4\n",
    "\n",
    "tenure_risk = TENURE_RISK[tenure_sample]\n",
    "acco_risk = ACCO_RISK[acco_type_sample]\n",
    "size_risk = SIZE_RISK[house_size_sample]\n",
    "internet_risk = INTERNET_RISK[internet_sample]\n",
    "employment_risk = EMPLOYMENT_RISK[num_adults_sample]\n",
    "deprivation_risk = DEPRIVATION_RISK[household_dep_sample]\n",
    "lifestage_risk = lifestage_risk_map(lifestage_sample)\n",
    "\n",
    "'''\n",
    "Deprivation: looks at 4 factors (higher weight)\n",
    "Employment: Income stability\n",
    "Employment: Wealth and security\n",
    "Others: Secondary modifiers\n",
    "'''\n",
    "WEIGHTS = {\n",
    "    \"tenure_risk\": 0.15,\n",
    "    \"acco_risk\": 0.10,\n",
    "    \"size_risk\": 0.10,\n",
    "    \"internet_risk\": 0.10,\n",
    "    \"lifestage_risk\": 0.10,\n",
    "    \"employment_risk\": 0.20,\n",
    "    \"deprivation_risk\": 0.25,\n",
    "}\n",
    " \n",
    "risk_score = (\n",
    "    WEIGHTS[\"tenure_risk\"]       * tenure_risk +\n",
    "    WEIGHTS[\"acco_risk\"]         * acco_risk +\n",
    "    WEIGHTS[\"size_risk\"]         * size_risk +\n",
    "    WEIGHTS[\"internet_risk\"]     * internet_risk +\n",
    "    WEIGHTS[\"lifestage_risk\"]    * lifestage_risk +\n",
    "    WEIGHTS[\"employment_risk\"]   * employment_risk +\n",
    "    WEIGHTS[\"deprivation_risk\"]  * deprivation_risk\n",
    ")\n",
    "\n",
    "print('Tenure -', tenure_sample)\n",
    "print('Accomodation type -', acco_type_sample)\n",
    "print('Household size -', house_size_sample)\n",
    "print('Internet access -', internet_sample)\n",
    "print('Adults employed -', num_adults_sample)\n",
    "print('Household deprivation -', household_dep_sample)\n",
    "print('Lifestage HRP -', lifestage_sample)\n",
    "\n",
    "noise = np.random.normal(loc=0, scale=0.03) \n",
    "household_risk_score = np.clip(risk_score + noise, 0, 1)\n",
    "print(household_risk_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccae853",
   "metadata": {},
   "source": [
    "### Road network density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9064b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the shapefile\n",
    "gdf = gpd.read_file(\"data/road/MotorwayJunction.shp\")\n",
    "\n",
    "# View the first few rows (attribute table)\n",
    "print(gdf.head())\n",
    "\n",
    "# Visualise the first few features on a map\n",
    "gdf.head().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63efe3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"data/road/RoadLink.shp\")\n",
    "\n",
    "# View the first few rows (attribute table)\n",
    "print(gdf.head())\n",
    "\n",
    "# Visualise the first few features on a map\n",
    "gdf.head().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cc3fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"data/road/RoadNode.shp\")\n",
    "\n",
    "# View the first few rows (attribute table)\n",
    "print(gdf.head())\n",
    "\n",
    "# Visualise the first few features on a map\n",
    "gdf.head().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ecaa28",
   "metadata": {},
   "source": [
    "### 51. Ambulance handover delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f96b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97f35968",
   "metadata": {},
   "source": [
    "### 52. Hospital bed availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359537da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dde2396",
   "metadata": {},
   "source": [
    "### 53. Historic flood map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c20afdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
